{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Importing required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_label(match):\n",
    "    ''' Derives a label for a given match. '''\n",
    "    \n",
    "    #Define variables\n",
    "    home_goals = match['home_team_goal']\n",
    "    away_goals = match['away_team_goal']\n",
    "     \n",
    "    label = pd.DataFrame()\n",
    "    label.loc[0,'match_api_id'] = match['match_api_id'] \n",
    "\n",
    "    #Identify match label  \n",
    "    if home_goals > away_goals:\n",
    "        label.loc[0,'label'] = \"Win\"\n",
    "    if home_goals == away_goals:\n",
    "        label.loc[0,'label'] = \"Draw\"\n",
    "    if home_goals < away_goals:\n",
    "        label.loc[0,'label'] = \"Defeat\"\n",
    "\n",
    "    #Return label        \n",
    "    return label.loc[0]\n",
    "    \n",
    "def get_fifa_stats(match, player_stats):\n",
    "    ''' Aggregates fifa stats for a given match. '''    \n",
    "    \n",
    "    #Define variables\n",
    "    match_id =  match.match_api_id\n",
    "    date = match['date']\n",
    "    players = ['home_player_1', 'home_player_2', 'home_player_3', \"home_player_4\", \"home_player_5\",\n",
    "               \"home_player_6\", \"home_player_7\", \"home_player_8\", \"home_player_9\", \"home_player_10\",\n",
    "               \"home_player_11\", \"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\",\n",
    "               \"away_player_5\", \"away_player_6\", \"away_player_7\", \"away_player_8\", \"away_player_9\",\n",
    "               \"away_player_10\", \"away_player_11\"]\n",
    "    player_stats_new = pd.DataFrame()\n",
    "    names = []\n",
    "    \n",
    "    #Loop through all players\n",
    "    for player in players:   \n",
    "            \n",
    "        #Get player ID\n",
    "        player_id = match[player]\n",
    "        \n",
    "        #Get player stats \n",
    "        stats = player_stats[player_stats.player_api_id == player_id]\n",
    "            \n",
    "        #Identify current stats       \n",
    "        current_stats = stats[stats.date < date].sort_values(by = 'date', ascending = False)[:1]\n",
    "        \n",
    "        if np.isnan(player_id) == True:\n",
    "            overall_rating = pd.Series(0)\n",
    "        else:\n",
    "            current_stats.reset_index(inplace = True, drop = True)\n",
    "            overall_rating = pd.Series(current_stats.loc[0, \"overall_rating\"])\n",
    "\n",
    "        #Rename stat\n",
    "        name = \"{}_overall_rating\".format(player)\n",
    "        names.append(name)\n",
    "            \n",
    "        #Aggregate stats\n",
    "        player_stats_new = pd.concat([player_stats_new, overall_rating], axis = 1)\n",
    "    \n",
    "    player_stats_new.columns = names        \n",
    "    player_stats_new['match_api_id'] = match_id\n",
    "\n",
    "    player_stats_new.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    #Return player stats    \n",
    "    return player_stats_new.iloc[0]     \n",
    "      \n",
    "def get_fifa_data(matches, player_stats, path = None, data_exists = False):\n",
    "    ''' Gets fifa data for all matches. '''  \n",
    "    \n",
    "    #Check if fifa data already exists\n",
    "    if data_exists == True:\n",
    "        \n",
    "        fifa_data = pd.read_pickle(path)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Collecting fifa data for each match...\")       \n",
    "        start = time()\n",
    "        \n",
    "        #Apply get_fifa_stats for each match\n",
    "        fifa_data = matches.apply(lambda x :get_fifa_stats(x, player_stats), axis = 1)\n",
    "        \n",
    "        end = time()    \n",
    "        print(\"Fifa data collected in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    #Return fifa_data\n",
    "    return fifa_data\n",
    "\n",
    "def get_overall_fifa_rankings(fifa, get_overall = False):\n",
    "    ''' Get overall fifa rankings from fifa data. '''\n",
    "      \n",
    "    temp_data = fifa\n",
    "    \n",
    "    #Check if only overall player stats are desired\n",
    "    if get_overall == True:\n",
    "        \n",
    "        #Get overall stats\n",
    "        data = temp_data.loc[:,(fifa.columns.str.contains('overall_rating'))]\n",
    "        data.loc[:,'match_api_id'] = temp_data.loc[:,'match_api_id']\n",
    "    else:\n",
    "        #Get all stats except for stat date\n",
    "        cols = fifa.loc[:,(fifa.columns.str.contains('date_stat'))]\n",
    "        temp_data = fifa.drop(cols.columns, axis = 1)        \n",
    "        data = temp_data\n",
    "    \n",
    "    #Return data\n",
    "    return data\n",
    "\n",
    "def get_last_matches(matches, date, team, x = 10):\n",
    "    ''' Get the last x matches of a given team. '''\n",
    "    \n",
    "    #Filter team matches from matches\n",
    "    team_matches = matches[(matches['home_team_api_id'] == team) | (matches['away_team_api_id'] == team)]\n",
    "                           \n",
    "    #Filter x last matches from team matches\n",
    "    last_matches = team_matches[team_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    \n",
    "    #Return last matches\n",
    "    return last_matches\n",
    "    \n",
    "def get_last_matches_against_eachother(matches, date, home_team, away_team, x = 10):\n",
    "    ''' Get the last x matches of two given teams. '''\n",
    "    \n",
    "    #Find matches of both teams\n",
    "    home_matches = matches[(matches['home_team_api_id'] == home_team) & (matches['away_team_api_id'] == away_team)]    \n",
    "    away_matches = matches[(matches['home_team_api_id'] == away_team) & (matches['away_team_api_id'] == home_team)]  \n",
    "    total_matches = pd.concat([home_matches, away_matches])\n",
    "    \n",
    "    #Get last x matches\n",
    "    try:    \n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    except:\n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:total_matches.shape[0],:]\n",
    "        \n",
    "        #Check for error in data\n",
    "        if(last_matches.shape[0] > x):\n",
    "            print(\"Error in obtaining matches\")\n",
    "            \n",
    "    #Return data\n",
    "    return last_matches\n",
    "    \n",
    "def get_goals(matches, team):\n",
    "    ''' Get the goals of a specfic team from a set of matches. '''\n",
    "    \n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.home_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.away_team_api_id == team].sum())\n",
    "\n",
    "    total_goals = home_goals + away_goals\n",
    "    \n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "\n",
    "def get_goals_conceided(matches, team):\n",
    "    ''' Get the goals conceided of a specfic team from a set of matches. '''\n",
    "\n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.away_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.home_team_api_id == team].sum())\n",
    "\n",
    "    total_goals = home_goals + away_goals\n",
    "\n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "\n",
    "def get_wins(matches, team):\n",
    "    ''' Get the number of wins of a specfic team from a set of matches. '''\n",
    "    \n",
    "    #Find home and away wins\n",
    "    home_wins = int(matches.home_team_goal[(matches.home_team_api_id == team) & (matches.home_team_goal > matches.away_team_goal)].count())\n",
    "    away_wins = int(matches.away_team_goal[(matches.away_team_api_id == team) & (matches.away_team_goal > matches.home_team_goal)].count())\n",
    "\n",
    "    total_wins = home_wins + away_wins\n",
    "\n",
    "    #Return total wins\n",
    "    return total_wins      \n",
    "    \n",
    "def get_match_features(match, matches, x = 10):\n",
    "    ''' Create match specific features for a given match. '''\n",
    "    \n",
    "    #Define variables\n",
    "    date = match.date\n",
    "    home_team = match.home_team_api_id\n",
    "    away_team = match.away_team_api_id\n",
    "    \n",
    "    #Get last x matches of home and away team\n",
    "    matches_home_team = get_last_matches(matches, date, home_team, x = 10)\n",
    "    matches_away_team = get_last_matches(matches, date, away_team, x = 10)\n",
    "    \n",
    "    #Get last x matches of both teams against each other\n",
    "    last_matches_against = get_last_matches_against_eachother(matches, date, home_team, away_team, x = 3)\n",
    "    \n",
    "    #Create goal variables\n",
    "    home_goals = get_goals(matches_home_team, home_team)\n",
    "    away_goals = get_goals(matches_away_team, away_team)\n",
    "    home_goals_conceided = get_goals_conceided(matches_home_team, home_team)\n",
    "    away_goals_conceided = get_goals_conceided(matches_away_team, away_team)\n",
    "    \n",
    "    #Define result data frame\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    #Define ID features\n",
    "    result.loc[0, 'match_api_id'] = match.match_api_id\n",
    "    result.loc[0, 'league_id'] = match.league_id\n",
    "\n",
    "    #Create match features\n",
    "    result.loc[0, 'home_team_goals_difference'] = home_goals - home_goals_conceided\n",
    "    result.loc[0, 'away_team_goals_difference'] = away_goals - away_goals_conceided\n",
    "    result.loc[0, 'games_won_home_team'] = get_wins(matches_home_team, home_team) \n",
    "    result.loc[0, 'games_won_away_team'] = get_wins(matches_away_team, away_team)\n",
    "    result.loc[0, 'games_against_home'] = get_wins(last_matches_against, home_team)\n",
    "    result.loc[0, 'games_against_away'] = get_wins(last_matches_against, away_team)\n",
    "    \n",
    "    #Return match features\n",
    "    return result.loc[0]\n",
    "    \n",
    "def create_feables(matches, fifa, bookkeepers, get_overall = False, horizontal = True, x = 10, verbose = True):\n",
    "    ''' Create and aggregate features and labels for all matches. '''\n",
    "\n",
    "\n",
    "    #Get fifa stats features\n",
    "    fifa_stats = get_overall_fifa_rankings(fifa, get_overall)\n",
    "\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Generating match features...\")\n",
    "    start = time()\n",
    "    \n",
    "    #Get match features for all matches\n",
    "    match_stats = matches.apply(lambda x: get_match_features(x, matches, x = 10), axis = 1)\n",
    "    #Create dummies for league ID feature\n",
    "    dummies = pd.get_dummies(match_stats['league_id']).rename(columns = lambda x: 'League_' + str(x))\n",
    "    match_stats = pd.concat([match_stats, dummies], axis = 1)\n",
    "    match_stats.drop(['league_id'], inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match features generated in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    if verbose == True:    \n",
    "        print(\"Generating match labels...\")\n",
    "    start = time()\n",
    "    \n",
    "    #Create match labels\n",
    "    labels = matches.apply(get_match_label, axis = 1)\n",
    "    \n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match labels generated in {:.1f} minutes\".format((end - start)/60))\n",
    "        \n",
    "    #Get bookkeeper quotas for all matches\n",
    "    bk_data = get_bookkeeper_data(matches, bookkeepers, horizontal = True)\n",
    "    bk_data.loc[:,'match_api_id'] = matches.loc[:,'match_api_id']\n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Bookkeeper data generated in {:.1f} minutes\".format((end - start)/60))\n",
    "\n",
    "    \n",
    "    #Merges features and labels into one frame\n",
    "    features = pd.merge(match_stats, fifa_stats, on = 'match_api_id', how = 'left')\n",
    "    features = pd.merge(features, bk_data, on = 'match_api_id', how = 'left')\n",
    "    feables = pd.merge(features, labels, on = 'match_api_id', how = 'left')\n",
    "    \n",
    "    #Drop NA values\n",
    "    feables.dropna(inplace = True)\n",
    "\n",
    "    #Return preprocessed data\n",
    "    return feables\n",
    "    \n",
    "def train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs, use_grid_search = True, \n",
    "                     best_components = None, best_params = None):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    #Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    \n",
    "    #Check if grid search should be applied\n",
    "    if use_grid_search == True: \n",
    "        \n",
    "        #Define pipeline of dm reduction and classifier\n",
    "        estimators = [('dm_reduce', dm_reduction), ('clf', clf)]\n",
    "        pipeline = Pipeline(estimators)\n",
    "        \n",
    "        #Grid search over pipeline and return best classifier\n",
    "        grid_obj = model_selection.GridSearchCV(pipeline, param_grid = params, scoring = scorer, cv = cv_sets, n_jobs = jobs)\n",
    "        grid_obj.fit(X_train, y_train)\n",
    "        best_pipe = grid_obj.best_estimator_\n",
    "    else:\n",
    "        \n",
    "        #Use best components that are known without grid search        \n",
    "        estimators = [('dm_reduce', dm_reduction(n_components = best_components)), ('clf', clf(best_params))]\n",
    "        pipeline = Pipeline(estimators)        \n",
    "        best_pipe = pipeline.fit(X_train, y_train)\n",
    "        \n",
    "    end = time()\n",
    "    \n",
    "    #Print the results\n",
    "    print(\"Trained {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "    \n",
    "    #Return best pipe\n",
    "    return best_pipe\n",
    "    \n",
    "def predict_labels(clf, best_pipe, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on scorer. '''\n",
    "    \n",
    "    #Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(best_pipe.named_steps['dm_reduce'].transform(features))\n",
    "    end = time()\n",
    "    \n",
    "    #Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds\".format(end - start))\n",
    "    return accuracy_score(target.values, y_pred)\n",
    "    \n",
    "def train_calibrate_predict(clf, dm_reduction, X_train, y_train, X_calibrate, y_calibrate, X_test, y_test, cv_sets, params, scorer, jobs, \n",
    "                            use_grid_search = True, **kwargs):\n",
    "    ''' Train and predict using a classifer based on scorer. '''\n",
    "    \n",
    "    #Indicate the classifier and the training set size\n",
    "    print(\"Training a {} with {}...\".format(clf.__class__.__name__, dm_reduction.__class__.__name__))\n",
    "    \n",
    "    #Train the classifier\n",
    "    best_pipe = train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs)\n",
    "    \n",
    "    #Calibrate classifier\n",
    "    print(\"Calibrating probabilities of classifier...\")\n",
    "    start = time()    \n",
    "    clf = CalibratedClassifierCV(best_pipe.named_steps['clf'], cv= 'prefit', method='isotonic')\n",
    "    clf.fit(best_pipe.named_steps['dm_reduce'].transform(X_calibrate), y_calibrate)\n",
    "    end = time()\n",
    "    print(\"Calibrated {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"Score of {} for training set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_train, y_train)))\n",
    "    print(\"Score of {} for test set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_test, y_test)))\n",
    "    \n",
    "    #Return classifier, dm reduction, and label predictions for train and test set\n",
    "    return clf, best_pipe.named_steps['dm_reduce'], predict_labels(clf, best_pipe, X_train, y_train), predict_labels(clf, best_pipe, X_test, y_test)\n",
    "        \n",
    "def convert_odds_to_prob(match_odds):\n",
    "    ''' Converts bookkeeper odds to probabilities. '''\n",
    "    \n",
    "    #Define variables\n",
    "    match_id = match_odds.loc[:,'match_api_id']\n",
    "    bookkeeper = match_odds.loc[:,'bookkeeper']    \n",
    "    win_odd = match_odds.loc[:,'Win']\n",
    "    draw_odd = match_odds.loc[:,'Draw']\n",
    "    loss_odd = match_odds.loc[:,'Defeat']\n",
    "    \n",
    "    #Converts odds to prob\n",
    "    win_prob = 1 / win_odd\n",
    "    draw_prob = 1 / draw_odd\n",
    "    loss_prob = 1 / loss_odd\n",
    "    \n",
    "    total_prob = win_prob + draw_prob + loss_prob\n",
    "    \n",
    "    probs = pd.DataFrame()\n",
    "    \n",
    "    #Define output format and scale probs by sum over all probs\n",
    "    probs.loc[:,'match_api_id'] = match_id\n",
    "    probs.loc[:,'bookkeeper'] = bookkeeper\n",
    "    probs.loc[:,'Win'] = win_prob / total_prob\n",
    "    probs.loc[:,'Draw'] = draw_prob / total_prob\n",
    "    probs.loc[:,'Defeat'] = loss_prob / total_prob\n",
    "    \n",
    "    #Return probs and meta data\n",
    "    return probs\n",
    "    \n",
    "def get_bookkeeper_data(matches, bookkeepers, horizontal = True):\n",
    "    ''' Aggregates bookkeeper data for all matches and bookkeepers. '''\n",
    "    \n",
    "    bk_data = pd.DataFrame()\n",
    "    \n",
    "    #Loop through bookkeepers\n",
    "    for bookkeeper in bookkeepers:\n",
    "\n",
    "        #Find columns containing data of bookkeeper\n",
    "        temp_data = matches.loc[:,(matches.columns.str.contains(bookkeeper))]\n",
    "        temp_data.loc[:, 'bookkeeper'] = str(bookkeeper)\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "        \n",
    "        #Rename odds columns and convert to numeric\n",
    "        cols = temp_data.columns.values\n",
    "        cols[:3] = ['Win','Draw','Defeat']\n",
    "        temp_data.columns = cols\n",
    "        temp_data.loc[:,'Win'] = pd.to_numeric(temp_data['Win'])\n",
    "        temp_data.loc[:,'Draw'] = pd.to_numeric(temp_data['Draw'])\n",
    "        temp_data.loc[:,'Defeat'] = pd.to_numeric(temp_data['Defeat'])\n",
    "        \n",
    "        #Check if data should be aggregated horizontally\n",
    "        if(horizontal == True):\n",
    "            \n",
    "            #Convert data to probs\n",
    "            temp_data = convert_odds_to_prob(temp_data)\n",
    "            temp_data.drop('match_api_id', axis = 1, inplace = True)\n",
    "            temp_data.drop('bookkeeper', axis = 1, inplace = True)\n",
    "            \n",
    "            #Rename columns with bookkeeper names\n",
    "            win_name = bookkeeper + \"_\" + \"Win\"\n",
    "            draw_name = bookkeeper + \"_\" + \"Draw\"\n",
    "            defeat_name = bookkeeper + \"_\" + \"Defeat\"\n",
    "            temp_data.columns.values[:3] = [win_name, draw_name, defeat_name]\n",
    "\n",
    "            #Aggregate data\n",
    "            bk_data = pd.concat([bk_data, temp_data], axis = 1)\n",
    "        else:\n",
    "            #Aggregate vertically\n",
    "            bk_data = bk_data.append(temp_data, ignore_index = True)\n",
    "    \n",
    "    #If horizontal add match api id to data\n",
    "    if(horizontal == True):\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "    \n",
    "    #Return bookkeeper data\n",
    "    return bk_data\n",
    "    \n",
    "def get_bookkeeper_probs(matches, bookkeepers, horizontal = False):\n",
    "    ''' Get bookkeeper data and convert to probabilities for vertical aggregation. '''\n",
    "    \n",
    "    #Get bookkeeper data\n",
    "    data = get_bookkeeper_data(matches, bookkeepers, horizontal = False)\n",
    "    \n",
    "    #Convert odds to probabilities\n",
    "    probs = convert_odds_to_prob(data)\n",
    "    \n",
    "    #Return data\n",
    "    return probs\n",
    "\n",
    "def plot_confusion_matrix(y_test, X_test, clf, dim_reduce, path, cmap=plt.cm.Blues, normalize = False):    \n",
    "    ''' Plot confusion matrix for given classifier and data. '''\n",
    "    \n",
    "    #Define label names and get confusion matrix values\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, clf.predict(dim_reduce.transform(X_test)), labels)\n",
    "    \n",
    "    #Check if matrix should be normalized\n",
    "    if normalize == True:\n",
    "        \n",
    "        #Normalize\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Configure figure\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title= \"Confusion matrix of a {} with {}\".format(best_clf.base_estimator.__class__.__name__, best_dm_reduce.__class__.__name__)   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report\n",
    "    y_pred = clf.predict(dim_reduce.transform(X_test))\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "\n",
    "def compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False):\n",
    "    ''' Map bookkeeper and model probabilities. '''\n",
    "    \n",
    "    #Create features and labels for given matches\n",
    "    feables = create_feables(matches, fifa_data, bk, get_overall = True, verbose = False)\n",
    "    \n",
    "    #Ensure consistency\n",
    "    match_ids = list(feables['match_api_id'])\n",
    "    matches = matches[matches['match_api_id'].isin(match_ids)]\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Obtaining bookkeeper probabilities...\")\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    inputs = feables.drop('match_api_id', axis = 1)\n",
    "    labels = inputs.loc[:,'label']\n",
    "    features = inputs.drop('label', axis = 1)\n",
    "    \n",
    "    #Get model probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Predicting probabilities based on model...\")\n",
    "    model_probs = pd.DataFrame()\n",
    "    label_table = pd.Series()\n",
    "    temp_probs = pd.DataFrame(clf.predict_proba(dim_reduce.transform(features)), columns = ['win_prob', 'draw_prob', 'defeat_prob'])\n",
    "    for bookkeeper in bookkeepers:\n",
    "        model_probs = model_probs.append(temp_probs, ignore_index = True)\n",
    "        label_table = label_table.append(labels)\n",
    "    model_probs.reset_index(inplace = True, drop = True)\n",
    "    label_table.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs['win_prob'] = model_probs['win_prob']\n",
    "    bookkeeper_probs['draw_prob'] = model_probs['draw_prob']\n",
    "    bookkeeper_probs['defeat_prob'] = model_probs['defeat_prob']\n",
    "    bookkeeper_probs['label'] = label_table \n",
    "    \n",
    "    #Aggregate win probabilities for each match\n",
    "    wins = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Win', 'win_prob', 'label']]\n",
    "    wins.loc[:, 'bet'] = 'Win'\n",
    "    wins = wins.rename(columns = {'Win':'bookkeeper_prob',\n",
    "                                  'win_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate draw probabilities for each match\n",
    "    draws = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Draw', 'draw_prob', 'label']]\n",
    "    draws.loc[:, 'bet'] = 'Draw'\n",
    "    draws = draws.rename(columns = {'Draw':'bookkeeper_prob',\n",
    "                                  'draw_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate defeat probabilities for each match\n",
    "    defeats = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Defeat', 'defeat_prob', 'label']]\n",
    "    defeats.loc[:, 'bet'] = 'Defeat'\n",
    "    defeats = defeats.rename(columns = {'Defeat':'bookkeeper_prob',\n",
    "                                  'defeat_prob': 'model_prob'})\n",
    "    \n",
    "    total = pd.concat([wins, draws, defeats])\n",
    "    \n",
    "    #Return total\n",
    "    return total\n",
    "    \n",
    "def find_good_bets(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, percentile, prob_cap, verbose = False):\n",
    "    ''' Find good bets for a given classifier and matches. '''\n",
    "    \n",
    "    #Compare model and classifier probabilities\n",
    "    probs = compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False)\n",
    "    probs.loc[:, 'prob_difference'] = probs.loc[:,\"model_prob\"] - probs.loc[:,\"bookkeeper_prob\"]\n",
    "    \n",
    "    #Sort by createst difference to identify most underestimated bets    \n",
    "    values = probs['prob_difference']\n",
    "    values = values.sort_values(ascending = False)\n",
    "    values.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Selecting attractive bets...\")\n",
    "        \n",
    "    #Identify choices that fulfill requirements such as positive difference, minimum probability and match outcome\n",
    "    relevant_choices = probs[(probs.prob_difference > 0) & (probs.model_prob > prob_cap) & (probs.bet != \"Draw\")]\n",
    "    \n",
    "    #Select given percentile of relevant choices    \n",
    "    top_percent = 1 - percentile\n",
    "    choices = relevant_choices[relevant_choices.prob_difference >= relevant_choices.prob_difference.quantile(top_percent)]\n",
    "    choices.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #Return choices\n",
    "    return choices\n",
    "\n",
    "def get_reward(choice, matches):\n",
    "    ''' Get the reward of a given bet. '''\n",
    "    \n",
    "    #Identify bet\n",
    "    match = matches[matches.match_api_id == choice.match_api_id]\n",
    "    bet_data = match.loc[:,(match.columns.str.contains(choice.bookkeeper))]\n",
    "    cols = bet_data.columns.values\n",
    "    cols[:3] = ['win','draw','defeat']\n",
    "    bet_data.columns = cols\n",
    "    \n",
    "    #Identfiy bet type and get quota\n",
    "    if choice.bet == 'Win':\n",
    "        bet_quota = bet_data.win.values\n",
    "    elif choice.bet == 'Draw':\n",
    "        bet_quota = bet_data.draw.values\n",
    "    elif choice.bet == 'Defeat':\n",
    "        bet_quota = bet_data.defeat.values\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    \n",
    "    #Check label and compute reward\n",
    "    if choice.bet == choice.label:\n",
    "        reward = bet_quota\n",
    "    else:\n",
    "        reward = 0\n",
    "    \n",
    "    #Return reward\n",
    "    return reward\n",
    "      \n",
    "def execute_bets(bet_choices, matches, verbose = False):\n",
    "    ''' Get rewards for all bets. '''    \n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Obtaining reward for chosen bets...\")\n",
    "    total_reward = 0\n",
    "    total_invested = 0\n",
    "    \n",
    "    #Loop through bets\n",
    "    loops = np.arange(0, bet_choices.shape[0])     \n",
    "    for i in loops:\n",
    "        \n",
    "        #Get rewards and accumulate profit\n",
    "        reward = get_reward(bet_choices.iloc[i,:], matches)\n",
    "        total_reward = total_reward + reward\n",
    "        total_invested += 1\n",
    "    \n",
    "    #Compute investment return\n",
    "    investment_return = float(total_reward / total_invested) - 1\n",
    "    \n",
    "    #Return investment return\n",
    "    return investment_return\n",
    "    \n",
    "def explore_data(features, inputs, path):\n",
    "    ''' Explore data by plotting KDE graphs. '''\n",
    "    \n",
    "    #Define figure subplots\n",
    "    fig = plt.figure(1)\n",
    "    fig.subplots_adjust(bottom= -1, left=0.025, top = 2, right=0.975)\n",
    "    \n",
    "    #Loop through features    \n",
    "    i = 1\n",
    "    for col in features.columns:\n",
    "        \n",
    "        #Set subplot and plot format        \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set_context(\"paper\", font_scale = 0.5, rc={\"lines.linewidth\": 1})\n",
    "        plt.subplot(7,7,0 + i)\n",
    "        j = i - 1\n",
    "        \n",
    "        #Plot KDE for all labels\n",
    "        sns.distplot(inputs[inputs['label'] == 'Win'].iloc[:,j], hist = False, label = 'Win')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Draw'].iloc[:,j], hist = False, label = 'Draw')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Defeat'].iloc[:,j], hist = False, label = 'Defeat')\n",
    "        plt.legend();\n",
    "        i = i + 1\n",
    "    \n",
    "    #Define plot format    \n",
    "    #DefaultSize = fig.get_size_inches()\n",
    "    fig.set_size_inches((DefaultSize[0]*1.2, DefaultSize[1]*1.2))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #Compute and print label weights\n",
    "    labels = inputs.loc[:,'label']\n",
    "    class_weights = labels.value_counts() / len(labels)\n",
    "    print(class_weights)\n",
    "    \n",
    "    #Store description of all features\n",
    "    feature_details = features.describe().transpose()\n",
    "\n",
    "    #Return feature details\n",
    "    return feature_details\n",
    "    \n",
    "def find_best_classifier(classifiers, dm_reductions, scorer, X_t, y_t, X_c, y_c, X_v, y_v, cv_sets, params, jobs):\n",
    "    ''' Tune all classifier and dimensionality reduction combiantions to find best classifier. '''\n",
    "    \n",
    "    #Initialize result storage\n",
    "    clfs_return = []\n",
    "    dm_reduce_return = []\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    #Loop through dimensionality reductions\n",
    "    for dm in dm_reductions:\n",
    "        \n",
    "        #Loop through classifiers\n",
    "        for clf in clfs:\n",
    "            \n",
    "            #Grid search, calibrate, and test the classifier\n",
    "            clf, dm_reduce, train_score, test_score = train_calibrate_predict(clf = clf, dm_reduction = dm, X_train = X_t, y_train = y_t,\n",
    "                                                      X_calibrate = X_c, y_calibrate = y_c,\n",
    "                                                      X_test = X_v, y_test = y_v, cv_sets = cv_sets,\n",
    "                                                      params = params[clf], scorer = scorer, jobs = jobs, use_grid_search = True)\n",
    "            \n",
    "            #Append the result to storage            \n",
    "            clfs_return.append(clf)\n",
    "            dm_reduce_return.append(dm_reduce)\n",
    "            train_scores.append(train_score)\n",
    "            test_scores.append(test_score)\n",
    "    \n",
    "    #Return storage\n",
    "    return clfs_return, dm_reduce_return, train_scores, test_scores\n",
    "\n",
    "def plot_training_results(clfs, dm_reductions, train_scores, test_scores, path):\n",
    "    ''' Plot results of classifier training. '''\n",
    "    \n",
    "    #Set graph format\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale = 1, rc={\"lines.linewidth\": 1})\n",
    "    ax = plt.subplot(111)\n",
    "    w = 0.5\n",
    "    x = np.arange(len(train_scores))\n",
    "    ax.set_yticks(x + w)\n",
    "    ax.legend((train_scores[0], test_scores[0]), (\"Train Scores\", \"Test Scores\"))\n",
    "    names = []\n",
    "    \n",
    "    #Loop throuugh classifiers\n",
    "    for i in range(0, len(clfs)): \n",
    "        \n",
    "        #Define temporary variables        \n",
    "        clf = clfs[i]\n",
    "        clf_name = clf.base_estimator.__class__.__name__\n",
    "        dm = dm_reductions[i]\n",
    "        dm_name = dm.__class__.__name__\n",
    "        \n",
    "        #Create and store name\n",
    "        name = \"{} with {}\".format(clf_name, dm_name)\n",
    "        names.append(name)\n",
    "        \n",
    "    #Plot all names in horizontal bar plot\n",
    "    ax.set_yticklabels((names))\n",
    "    plt.xlim(0.5, 0.55)\n",
    "    plt.barh(x, test_scores, color = 'b', alpha = 0.6)\n",
    "    plt.title(\"Test Data Accuracy Scores\")\n",
    "    fig = plt.figure(1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def optimize_betting(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, match_data, fifa_data,\n",
    "                     n_samples, sample_size, parameter_1_grid, parameter_2_grid, verbose = False):\n",
    "    ''' Tune parameters of bet selection algorithm. '''\n",
    "    \n",
    "    #Generate data samples\n",
    "    samples = []\n",
    "    for i in range(0, n_samples):\n",
    "        sample = match_data.sample(n = sample_size, random_state = 42)\n",
    "        samples.append(sample)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [\"parameter_1\", \"parameter_2\", \"results\"])\n",
    "    row = 0\n",
    "    \n",
    "    #Iterate over all 1 parameter\n",
    "    for i in parameter_1_grid:\n",
    "        \n",
    "        #Iterate over all 2 parameter\n",
    "        for j in parameter_2_grid:\n",
    "            \n",
    "            #Compute average score over all samples\n",
    "            profits = []\n",
    "            for sample in samples:\n",
    "                choices = find_good_bets(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, sample, fifa_data, i, j)\n",
    "                profit = execute_bets(choices, match_data)\n",
    "                profits.append(profit)\n",
    "            result = np.mean(np.array(profits))\n",
    "            results.loc[row,\"results\"] = result\n",
    "            results.loc[row,\"parameter_1\"] = i\n",
    "            results.loc[row,\"parameter_2\"] = j\n",
    "            row = row + 1\n",
    "            if verbose == True: print(\"Simulated parameter combination: {}\".format(row))\n",
    "               \n",
    "    #Return best setting and result\n",
    "    best_result = results.ix[results['results'].idxmax()] \n",
    "    return best_result\n",
    "    \n",
    "    \n",
    "def plot_bookkeeper_cf_matrix(matches, bookkeepers, path, verbose = False, normalize = True):\n",
    "    ''' Plot confusion matrix of bookkeeper predictions. '''\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining labels...\")\n",
    "    \n",
    "    #Get match labels\n",
    "    y_test_temp = matches.apply(get_match_label, axis = 1)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper probabilities...\")\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs.dropna(inplace = True)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper labels...\")\n",
    "    \n",
    "    #Get bookkeeper labels\n",
    "    y_pred_temp = pd.DataFrame()\n",
    "    y_pred_temp.loc[:,'bk_label'] = bookkeeper_probs[['Win', 'Draw', 'Defeat']].idxmax(axis = 1)\n",
    "    y_pred_temp.loc[:,'match_api_id'] = bookkeeper_probs.loc[:, 'match_api_id']\n",
    "    \n",
    "    if verbose == True: print(\"Plotting confusion matrix...\")\n",
    "    \n",
    "    #Format data\n",
    "    results = pd.merge(y_pred_temp, y_test_temp, on = 'match_api_id', how = 'left')\n",
    "    y_test = results.loc[:, 'label']\n",
    "    y_pred = results.loc[:, 'bk_label']\n",
    "    \n",
    "    #Generate confusion matrix\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, y_pred, labels) \n",
    "    \n",
    "    #Check for normalization\n",
    "    if normalize == True:\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Plot confusion matrix\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title = \"Confusion matrix of Bookkeeper predictions!\"   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignmenSt=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report and accuracy score of bookkeepers\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "    print(\"Bookkeeper score for test set: {:.4f}.\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-477a508b8abb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplayer_stats_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM Player_Attributes;\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mteam_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM Team;\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM Match;\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Reduce match data to fulfill run time requirements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joão abelha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m         return pandas_sql.read_query(\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joão abelha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m   1644\u001b[0m             )\n\u001b[0;32m   1645\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetchall_as_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1647\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joão abelha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m_fetchall_as_list\u001b[1;34m(self, cur)\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fetchall_as_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Fetching data\n",
    "#Connecting to database\n",
    "path = \"\"\n",
    "database = path + 'database.sqlite'\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_colwidth',1000)\n",
    "\n",
    "# Fetching required data tables\n",
    "player_data = pd.read_sql(\"SELECT * FROM Player;\", conn)\n",
    "player_stats_data = pd.read_sql(\"SELECT * FROM Player_Attributes;\", conn)\n",
    "team_data = pd.read_sql(\"SELECT * FROM Team;\", conn)\n",
    "match_data = pd.read_sql(\"SELECT * FROM Match;\", conn)\n",
    "\n",
    "# Reduce match data to fulfill run time requirements\n",
    "rows = [\"country_id\", \"league_id\", \"season\", \"stage\", \"date\", \"match_api_id\", \"home_team_api_id\", \n",
    "        \"away_team_api_id\", \"home_team_goal\", \"away_team_goal\", \"home_player_1\", \"home_player_2\",\n",
    "        \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\", \n",
    "        \"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\", \"away_player_1\",\n",
    "        \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\",\n",
    "        \"away_player_7\", \"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"]\n",
    "\n",
    "# Drops rows with NaN values\n",
    "match_data.dropna(subset = rows, inplace = True)\n",
    "\n",
    "# We're only using 1500 matches right now!!!\n",
    "# match_data = match_data.head(1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating features, exploring the data, and preparing data for model training\n",
    "\n",
    "# Gets players fifa overall ratings for each match\n",
    "fifa_data = get_fifa_data(match_data, player_stats_data, data_exists = False)\n",
    "\n",
    "odds = ['B365', 'BW', 'IW', 'LB', 'PS', 'WH', 'SJ', 'VC', 'GB', 'BS']\n",
    "feables = create_feables(match_data, fifa_data, odds, get_overall = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "feables.to_csv(\"feables.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21374, 23)\n"
     ]
    }
   ],
   "source": [
    "input = feables\n",
    "input['odds_home'] = (input['B365_Win'] + input['BW_Win'] + input['IW_Win'] + input['LB_Win'] + input['PS_Win'] + input['WH_Win'] + input['SJ_Win'] + input['VC_Win'] + input['GB_Win'] + input['BS_Win']) / 10.0\n",
    "input['odds_draw'] = (input['B365_Draw'] + input['BW_Draw'] + input['IW_Draw'] + input['LB_Draw'] + input['PS_Draw'] + input['WH_Draw'] + input['SJ_Draw'] + input['VC_Draw'] + input['GB_Draw'] + input['BS_Draw']) / 10.0\n",
    "input['odds_away'] = (input['B365_Defeat'] + input['BW_Defeat'] + input['IW_Defeat'] + input['LB_Defeat'] + input['PS_Defeat'] + input['WH_Defeat'] + input['SJ_Defeat'] + input['VC_Defeat'] + input['GB_Defeat'] + input['BS_Defeat']) / 10.0\n",
    "\n",
    "# Reduce match data to fulfill run time requirements\n",
    "rows = [\"home_team_goals_difference\", \"away_team_goals_difference\", \"games_won_home_team\",\t\"games_won_away_team\",\t\"games_against_home\",\t\"games_against_away\",\"home_player_1_overall_rating\", \"home_player_2_overall_rating\",\n",
    "        \"home_player_3_overall_rating\", \"home_player_4_overall_rating\", \"home_player_5_overall_rating\", \"home_player_6_overall_rating\", \"home_player_7_overall_rating\", \n",
    "        \"home_player_8_overall_rating\", \"home_player_9_overall_rating\", \"home_player_10_overall_rating\", \"home_player_11_overall_rating\", \"away_player_1_overall_rating\",\n",
    "        \"away_player_2_overall_rating\", \"away_player_3_overall_rating\", \"away_player_4_overall_rating\", \"away_player_5_overall_rating\", \"away_player_6_overall_rating\",\n",
    "        \"away_player_7_overall_rating\", \"away_player_8_overall_rating\", \"away_player_9_overall_rating\", \"away_player_10_overall_rating\", \"away_player_11_overall_rating\", \"odds_home\", \"odds_draw\", \"odds_away\", \"label\"]\n",
    "\n",
    "input = input[rows]\n",
    "\n",
    "labels = input.loc[:,'label']\n",
    "print(fifa_data.shape)\n",
    "\n",
    "features = input.drop('label', axis = 1)\n",
    "labels.to_csv(\"labels.csv\", sep=',')\n",
    "features.to_csv(\"features.csv\", sep=',')\n",
    "\n",
    "# Features Columns\n",
    "\n",
    "# home_team_goals_difference - goals difference in the last 10 games\n",
    "#away_team_goals_difference - goals difference in the last 10 games\n",
    "#games_won_home_team - victories in the last 10 games\n",
    "#games_won_away_team - victories in the last 10 games\n",
    "#games_against_home - won games by the home team, between the two teams\n",
    "#games_against_away - won games by the visitor team, between the two teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Features      Score\n",
      "28                      odds_home  14.812595\n",
      "30                      odds_away  13.510082\n",
      "29                      odds_draw   9.411810\n",
      "3             games_won_away_team   9.164181\n",
      "1      away_team_goals_difference   9.001905\n",
      "19   away_player_3_overall_rating   6.916504\n",
      "7    home_player_2_overall_rating   6.635907\n",
      "18   away_player_2_overall_rating   6.362262\n",
      "14   home_player_9_overall_rating   5.053426\n",
      "10   home_player_5_overall_rating   5.029158\n",
      "12   home_player_7_overall_rating   4.029868\n",
      "27  away_player_11_overall_rating   4.027402\n",
      "26  away_player_10_overall_rating   3.875786\n",
      "0      home_team_goals_difference   3.662570\n",
      "15  home_player_10_overall_rating   3.634490\n",
      "4              games_against_home   3.499859\n",
      "23   away_player_7_overall_rating   3.386378\n",
      "6    home_player_1_overall_rating   3.114271\n",
      "16  home_player_11_overall_rating   2.940083\n",
      "22   away_player_6_overall_rating   2.717531\n",
      "20   away_player_4_overall_rating   2.584002\n",
      "24   away_player_8_overall_rating   2.564272\n",
      "2             games_won_home_team   2.493711\n",
      "5              games_against_away   2.428216\n",
      "13   home_player_8_overall_rating   2.030992\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "##### FEATURE SELECTION #####\n",
    "#############################\n",
    "\n",
    "# Univariate Selection - uses statistical tests that can be used to select those features that have the strongest relationship with the output variable.\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=25)\n",
    "fit = bestfeatures.fit(features, labels)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(features.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(25,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0249531  0.03312031 0.02880762 0.03759982 0.02199327 0.0291054\n",
      " 0.0332723  0.03357567 0.02683673 0.02793434 0.05011864 0.02609968\n",
      " 0.0299703  0.03232617 0.02570358 0.03038333 0.02746241 0.03499141\n",
      " 0.04566834 0.03395811 0.03983141 0.03914122 0.03594201 0.0290082\n",
      " 0.02787861 0.03594584 0.02064527 0.0260219  0.02860576 0.03785417\n",
      " 0.04524506]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################\n",
    "##### FEATURE SELECTION #####\n",
    "#############################\n",
    "\n",
    "# Feature Importance - uses statistical tests that can be used to select those features that have the strongest relationship with the output variable.       \n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(features, labels)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=features.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>variances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_team_goals_difference</td>\n",
       "      <td>2.725952e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>away_team_goals_difference</td>\n",
       "      <td>2.564478e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>games_won_home_team</td>\n",
       "      <td>6.217369e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>games_won_away_team</td>\n",
       "      <td>5.158144e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>games_against_home</td>\n",
       "      <td>3.112892e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>games_against_away</td>\n",
       "      <td>2.944180e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>home_player_1_overall_rating</td>\n",
       "      <td>2.630048e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>home_player_2_overall_rating</td>\n",
       "      <td>2.500191e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_player_3_overall_rating</td>\n",
       "      <td>2.449763e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_player_4_overall_rating</td>\n",
       "      <td>2.228747e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>home_player_5_overall_rating</td>\n",
       "      <td>1.952686e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home_player_6_overall_rating</td>\n",
       "      <td>1.837246e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_player_7_overall_rating</td>\n",
       "      <td>1.676188e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>home_player_8_overall_rating</td>\n",
       "      <td>1.652000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>home_player_9_overall_rating</td>\n",
       "      <td>1.564932e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>home_player_10_overall_rating</td>\n",
       "      <td>1.536035e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_player_11_overall_rating</td>\n",
       "      <td>1.402482e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_player_1_overall_rating</td>\n",
       "      <td>1.351884e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>away_player_2_overall_rating</td>\n",
       "      <td>1.297806e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>away_player_3_overall_rating</td>\n",
       "      <td>1.201229e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>away_player_4_overall_rating</td>\n",
       "      <td>1.102866e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>away_player_5_overall_rating</td>\n",
       "      <td>1.024792e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>away_player_6_overall_rating</td>\n",
       "      <td>9.256787e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_player_7_overall_rating</td>\n",
       "      <td>7.379030e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>away_player_8_overall_rating</td>\n",
       "      <td>2.006986e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>away_player_9_overall_rating</td>\n",
       "      <td>1.709585e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>away_player_10_overall_rating</td>\n",
       "      <td>1.524401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>away_player_11_overall_rating</td>\n",
       "      <td>6.582069e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>odds_home</td>\n",
       "      <td>6.345128e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>odds_draw</td>\n",
       "      <td>8.578568e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>odds_away</td>\n",
       "      <td>1.796257e-33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features     variances\n",
       "0      home_team_goals_difference  2.725952e-01\n",
       "1      away_team_goals_difference  2.564478e-01\n",
       "2             games_won_home_team  6.217369e-02\n",
       "3             games_won_away_team  5.158144e-02\n",
       "4              games_against_home  3.112892e-02\n",
       "5              games_against_away  2.944180e-02\n",
       "6    home_player_1_overall_rating  2.630048e-02\n",
       "7    home_player_2_overall_rating  2.500191e-02\n",
       "8    home_player_3_overall_rating  2.449763e-02\n",
       "9    home_player_4_overall_rating  2.228747e-02\n",
       "10   home_player_5_overall_rating  1.952686e-02\n",
       "11   home_player_6_overall_rating  1.837246e-02\n",
       "12   home_player_7_overall_rating  1.676188e-02\n",
       "13   home_player_8_overall_rating  1.652000e-02\n",
       "14   home_player_9_overall_rating  1.564932e-02\n",
       "15  home_player_10_overall_rating  1.536035e-02\n",
       "16  home_player_11_overall_rating  1.402482e-02\n",
       "17   away_player_1_overall_rating  1.351884e-02\n",
       "18   away_player_2_overall_rating  1.297806e-02\n",
       "19   away_player_3_overall_rating  1.201229e-02\n",
       "20   away_player_4_overall_rating  1.102866e-02\n",
       "21   away_player_5_overall_rating  1.024792e-02\n",
       "22   away_player_6_overall_rating  9.256787e-03\n",
       "23   away_player_7_overall_rating  7.379030e-03\n",
       "24   away_player_8_overall_rating  2.006986e-03\n",
       "25   away_player_9_overall_rating  1.709585e-03\n",
       "26  away_player_10_overall_rating  1.524401e-03\n",
       "27  away_player_11_overall_rating  6.582069e-04\n",
       "28                      odds_home  6.345128e-06\n",
       "29                      odds_draw  8.578568e-07\n",
       "30                      odds_away  1.796257e-33"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################\n",
    "##### FEATURE SELECTION #####\n",
    "#############################\n",
    "\n",
    "# Principal Component Analysis (PCA) - using the data covariance and it's eigenvalue decomposition, calculates the most relevant features on the dataset\n",
    "pca = PCA(n_components=31)\n",
    "pca.fit(features)\n",
    "variances = pd.DataFrame()\n",
    "variances.loc[:,'features'] = features.columns\n",
    "variances.loc[:,'variances'] = pca.explained_variance_ratio_ \n",
    "\n",
    "variances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Results (poderão mudar se alterarmos as variáveis iniciais)\n",
    "\n",
    "By analyzing the results of the 3 techniques applied (Univariate Selection, Feature Importance and PCA) we can conclude that there isn't any feature that has a special relevance on the output. Meaning that the output depends not of a specific feature, but of the features as a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Use of DecisionTreeClassifier with and without k-fold cross-validation,  GridSearchCV for parameter tunning \n",
    "and use of Random Forest Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c90482730658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mall_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "all_inputs = input.loc[:, input.columns != 'label'].values\n",
    "all_labels = input.label.values\n",
    "\n",
    "#all_inputs[:5]\n",
    "\n",
    "(training_inputs,\n",
    " testing_inputs,\n",
    " training_classes,\n",
    " testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decion tree classifier (not very good classifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "decision_tree_classifier.fit(training_inputs, training_classes)\n",
    "\n",
    "# Validate the classifier on the testing set using classification accuracy\n",
    "decision_tree_classifier.score(testing_inputs, testing_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from this we can see that the problem is dependent on the subset we are\n",
    "# using => overfitting\n",
    "model_accuracies = []\n",
    "\n",
    "for repetition in range(1000):\n",
    "    (training_inputs,\n",
    "     testing_inputs,\n",
    "     training_classes,\n",
    "     testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25)\n",
    "    \n",
    "    decision_tree_classifier = DecisionTreeClassifier()\n",
    "    decision_tree_classifier.fit(training_inputs, training_classes)\n",
    "    classifier_accuracy = decision_tree_classifier.score(testing_inputs, testing_classes)\n",
    "    model_accuracies.append(classifier_accuracy)\n",
    "    \n",
    "plt.hist(model_accuracies)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation\n",
    "def plot_cv(cv, features, labels):\n",
    "    masks = []\n",
    "    for train, test in cv.split(features, labels):\n",
    "        mask = np.zeros(len(labels), dtype=bool)\n",
    "        mask[test] = 1\n",
    "        masks.append(mask)\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(masks, interpolation='none', cmap='gray_r')\n",
    "    plt.ylabel('Fold')\n",
    "    plt.xlabel('Row #')\n",
    "\n",
    "plot_cv(StratifiedKFold(n_splits=10), all_inputs, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a more consistent rating: however is not that good\n",
    "from sklearn.model_selection import cross_val_score\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# cross_val_score returns a list of the scores, which we can visualize\n",
    "# to get a reasonable estimate of our classifier's performance\n",
    "cv_scores = cross_val_score(decision_tree_classifier, all_inputs, all_labels, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "cv_scores = cross_val_score(decision_tree_classifier, all_inputs, all_labels, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "parameter_grid = {'max_depth': [1, 2, 3, 4, 5],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree_classifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_visualization = grid_search.cv_results_['mean_test_score']\n",
    "grid_visualization.shape = (5, 4)\n",
    "sns.heatmap(grid_visualization, cmap='Blues', annot=True)\n",
    "plt.xticks(np.arange(4) + 0.5, grid_search.param_grid['max_features'])\n",
    "plt.yticks(np.arange(5) + 0.5, grid_search.param_grid['max_depth'])\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('max_depth')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "                  'splitter': ['best', 'random'],\n",
    "                  'max_depth': [1, 2, 3, 4, 5],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree_classifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = grid_search.best_estimator_\n",
    "decision_tree_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "\n",
    "parameter_grid = {'n_estimators': [10, 25, 50, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(random_forest_classifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_forest_classifier = grid_search.best_estimator_\n",
    "\n",
    "rf_df = pd.DataFrame({'accuracy': cross_val_score(random_forest_classifier, all_inputs, all_labels, cv=10),\n",
    "                       'classifier': ['Random Forest'] * 10})\n",
    "dt_df = pd.DataFrame({'accuracy': cross_val_score(decision_tree_classifier, all_inputs, all_labels, cv=10),\n",
    "                      'classifier': ['Decision Tree'] * 10})\n",
    "both_df = rf_df.append(dt_df)\n",
    "\n",
    "sns.boxplot(x='classifier', y='accuracy', data=both_df)\n",
    "sns.stripplot(x='classifier', y='accuracy', data=both_df, jitter=True, color='black')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read processed data from file\n",
    "\n",
    "<p>Reading the labels and the features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      home_team_goals_difference  away_team_goals_difference  \\\n",
      "0                           -9.0                         7.0   \n",
      "1                           -5.0                       -12.0   \n",
      "2                            5.0                         3.0   \n",
      "3                            0.0                        -5.0   \n",
      "4                           11.0                         0.0   \n",
      "5                            6.0                        -7.0   \n",
      "6                           14.0                         7.0   \n",
      "7                            2.0                        10.0   \n",
      "8                           -2.0                         0.0   \n",
      "9                           -9.0                        -4.0   \n",
      "10                           3.0                       -14.0   \n",
      "11                          -1.0                        -3.0   \n",
      "12                           1.0                         2.0   \n",
      "13                         -10.0                         0.0   \n",
      "14                           8.0                       -10.0   \n",
      "15                           5.0                         0.0   \n",
      "16                           2.0                         2.0   \n",
      "17                           6.0                        -2.0   \n",
      "18                           4.0                        13.0   \n",
      "19                          -2.0                       -13.0   \n",
      "20                          -1.0                         2.0   \n",
      "21                         -15.0                         0.0   \n",
      "22                           8.0                        -1.0   \n",
      "23                           1.0                       -15.0   \n",
      "24                          -1.0                        -2.0   \n",
      "25                          -1.0                        10.0   \n",
      "26                         -10.0                        10.0   \n",
      "27                           3.0                         8.0   \n",
      "28                          -1.0                        -1.0   \n",
      "29                         -12.0                         2.0   \n",
      "...                          ...                         ...   \n",
      "2597                         3.0                       -14.0   \n",
      "2598                        11.0                         5.0   \n",
      "2599                        -3.0                         2.0   \n",
      "2600                       -14.0                        -4.0   \n",
      "2601                        -3.0                         3.0   \n",
      "2602                         3.0                        -7.0   \n",
      "2603                         4.0                        -8.0   \n",
      "2604                        -1.0                         2.0   \n",
      "2605                        26.0                        17.0   \n",
      "2606                       -16.0                        -5.0   \n",
      "2607                       -12.0                        -8.0   \n",
      "2608                         4.0                         1.0   \n",
      "2609                        -3.0                        12.0   \n",
      "2610                        -5.0                        -1.0   \n",
      "2611                         3.0                       -11.0   \n",
      "2612                        -4.0                        -4.0   \n",
      "2613                        -5.0                         1.0   \n",
      "2614                         3.0                         1.0   \n",
      "2615                        14.0                         1.0   \n",
      "2616                        -6.0                        19.0   \n",
      "2617                        -8.0                         4.0   \n",
      "2618                         0.0                        -4.0   \n",
      "2619                        13.0                        -1.0   \n",
      "2620                        -2.0                         0.0   \n",
      "2621                        -9.0                        -5.0   \n",
      "2622                        -2.0                        -7.0   \n",
      "2623                         3.0                         5.0   \n",
      "2624                        -1.0                        13.0   \n",
      "2625                        -1.0                        -8.0   \n",
      "2626                        -8.0                        17.0   \n",
      "\n",
      "      games_won_home_team  games_won_away_team  games_against_home  \\\n",
      "0                     2.0                  6.0                 0.0   \n",
      "1                     2.0                  1.0                 0.0   \n",
      "2                     5.0                  4.0                 0.0   \n",
      "3                     4.0                  2.0                 0.0   \n",
      "4                     8.0                  0.0                 0.0   \n",
      "5                     5.0                  4.0                 2.0   \n",
      "6                     7.0                  5.0                 0.0   \n",
      "7                     4.0                  6.0                 0.0   \n",
      "8                     4.0                  4.0                 1.0   \n",
      "9                     2.0                  2.0                 0.0   \n",
      "10                    5.0                  1.0                 1.0   \n",
      "11                    4.0                  1.0                 1.0   \n",
      "12                    3.0                  5.0                 0.0   \n",
      "13                    0.0                  4.0                 0.0   \n",
      "14                    5.0                  0.0                 0.0   \n",
      "15                    4.0                  4.0                 2.0   \n",
      "16                    4.0                  5.0                 3.0   \n",
      "17                    6.0                  3.0                 0.0   \n",
      "18                    3.0                  6.0                 1.0   \n",
      "19                    1.0                  2.0                 1.0   \n",
      "20                    3.0                  4.0                 0.0   \n",
      "21                    1.0                  3.0                 2.0   \n",
      "22                    5.0                  3.0                 3.0   \n",
      "23                    4.0                  1.0                 1.0   \n",
      "24                    3.0                  3.0                 1.0   \n",
      "25                    4.0                  4.0                 1.0   \n",
      "26                    3.0                  6.0                 0.0   \n",
      "27                    6.0                  5.0                 1.0   \n",
      "28                    3.0                  1.0                 1.0   \n",
      "29                    0.0                  5.0                 0.0   \n",
      "...                   ...                  ...                 ...   \n",
      "2597                  5.0                  0.0                 0.0   \n",
      "2598                  7.0                  5.0                 1.0   \n",
      "2599                  4.0                  5.0                 0.0   \n",
      "2600                  1.0                  3.0                 2.0   \n",
      "2601                  4.0                  4.0                 0.0   \n",
      "2602                  6.0                  2.0                 2.0   \n",
      "2603                  6.0                  2.0                 0.0   \n",
      "2604                  2.0                  4.0                 0.0   \n",
      "2605                  9.0                  7.0                 1.0   \n",
      "2606                  3.0                  2.0                 0.0   \n",
      "2607                  0.0                  4.0                 2.0   \n",
      "2608                  5.0                  4.0                 2.0   \n",
      "2609                  4.0                  8.0                 0.0   \n",
      "2610                  3.0                  5.0                 1.0   \n",
      "2611                  4.0                  2.0                 2.0   \n",
      "2612                  3.0                  4.0                 1.0   \n",
      "2613                  3.0                  5.0                 1.0   \n",
      "2614                  4.0                  5.0                 1.0   \n",
      "2615                  6.0                  3.0                 0.0   \n",
      "2616                  2.0                  8.0                 0.0   \n",
      "2617                  1.0                  5.0                 0.0   \n",
      "2618                  4.0                  4.0                 0.0   \n",
      "2619                  9.0                  3.0                 2.0   \n",
      "2620                  4.0                  4.0                 1.0   \n",
      "2621                  2.0                  3.0                 0.0   \n",
      "2622                  5.0                  2.0                 1.0   \n",
      "2623                  6.0                  5.0                 0.0   \n",
      "2624                  4.0                  6.0                 0.0   \n",
      "2625                  3.0                  1.0                 0.0   \n",
      "2626                  4.0                  8.0                 0.0   \n",
      "\n",
      "      games_against_away  home_player_1_overall_rating  \\\n",
      "0                    1.0                          71.0   \n",
      "1                    1.0                          64.0   \n",
      "2                    2.0                          69.0   \n",
      "3                    0.0                          69.0   \n",
      "4                    0.0                          65.0   \n",
      "5                    1.0                          66.0   \n",
      "6                    3.0                          71.0   \n",
      "7                    3.0                          71.0   \n",
      "8                    1.0                          71.0   \n",
      "9                    0.0                          57.0   \n",
      "10                   1.0                          68.0   \n",
      "11                   0.0                          72.0   \n",
      "12                   2.0                          65.0   \n",
      "13                   0.0                          65.0   \n",
      "14                   0.0                          74.0   \n",
      "15                   1.0                          65.0   \n",
      "16                   0.0                          71.0   \n",
      "17                   1.0                          68.0   \n",
      "18                   1.0                          66.0   \n",
      "19                   0.0                          63.0   \n",
      "20                   1.0                          63.0   \n",
      "21                   1.0                          67.0   \n",
      "22                   0.0                          71.0   \n",
      "23                   1.0                          71.0   \n",
      "24                   0.0                          71.0   \n",
      "25                   1.0                          71.0   \n",
      "26                   0.0                          57.0   \n",
      "27                   1.0                          66.0   \n",
      "28                   0.0                          65.0   \n",
      "29                   0.0                          65.0   \n",
      "...                  ...                           ...   \n",
      "2597                 0.0                          72.0   \n",
      "2598                 1.0                          79.0   \n",
      "2599                 1.0                          57.0   \n",
      "2600                 1.0                          79.0   \n",
      "2601                 1.0                          75.0   \n",
      "2602                 0.0                          79.0   \n",
      "2603                 0.0                          77.0   \n",
      "2604                 0.0                          67.0   \n",
      "2605                 1.0                          85.0   \n",
      "2606                 0.0                          70.0   \n",
      "2607                 0.0                          77.0   \n",
      "2608                 0.0                          76.0   \n",
      "2609                 2.0                          66.0   \n",
      "2610                 1.0                          77.0   \n",
      "2611                 0.0                          79.0   \n",
      "2612                 1.0                          75.0   \n",
      "2613                 1.0                          76.0   \n",
      "2614                 0.0                          74.0   \n",
      "2615                 0.0                          89.0   \n",
      "2616                 2.0                          78.0   \n",
      "2617                 3.0                          77.0   \n",
      "2618                 0.0                          68.0   \n",
      "2619                 0.0                          79.0   \n",
      "2620                 2.0                          57.0   \n",
      "2621                 0.0                          79.0   \n",
      "2622                 1.0                          75.0   \n",
      "2623                 3.0                          79.0   \n",
      "2624                 2.0                          77.0   \n",
      "2625                 0.0                          76.0   \n",
      "2626                 1.0                          70.0   \n",
      "\n",
      "      home_player_2_overall_rating  home_player_3_overall_rating  \\\n",
      "0                             59.0                          61.0   \n",
      "1                             61.0                          69.0   \n",
      "2                             70.0                          72.0   \n",
      "3                             68.0                          69.0   \n",
      "4                             71.0                          72.0   \n",
      "5                             71.0                          65.0   \n",
      "6                             71.0                          73.0   \n",
      "7                             69.0                          70.0   \n",
      "8                             62.0                          67.0   \n",
      "9                             63.0                          62.0   \n",
      "10                            70.0                          67.0   \n",
      "11                            70.0                          69.0   \n",
      "12                            67.0                          70.0   \n",
      "13                            63.0                          64.0   \n",
      "14                            73.0                          74.0   \n",
      "15                            66.0                          64.0   \n",
      "16                            71.0                          73.0   \n",
      "17                            70.0                          67.0   \n",
      "18                            65.0                          70.0   \n",
      "19                            65.0                          64.0   \n",
      "20                            68.0                          64.0   \n",
      "21                            65.0                          63.0   \n",
      "22                            70.0                          71.0   \n",
      "23                            70.0                          61.0   \n",
      "24                            68.0                          73.0   \n",
      "25                            63.0                          62.0   \n",
      "26                            63.0                          62.0   \n",
      "27                            66.0                          65.0   \n",
      "28                            70.0                          66.0   \n",
      "29                            57.0                          63.0   \n",
      "...                            ...                           ...   \n",
      "2597                          72.0                          75.0   \n",
      "2598                          78.0                          78.0   \n",
      "2599                          72.0                          75.0   \n",
      "2600                          78.0                          74.0   \n",
      "2601                          72.0                          76.0   \n",
      "2602                          76.0                          74.0   \n",
      "2603                          72.0                          76.0   \n",
      "2604                          74.0                          72.0   \n",
      "2605                          84.0                          86.0   \n",
      "2606                          72.0                          68.0   \n",
      "2607                          73.0                          76.0   \n",
      "2608                          77.0                          79.0   \n",
      "2609                          71.0                          74.0   \n",
      "2610                          71.0                          73.0   \n",
      "2611                          73.0                          84.0   \n",
      "2612                          75.0                          76.0   \n",
      "2613                          73.0                          73.0   \n",
      "2614                          74.0                          77.0   \n",
      "2615                          87.0                          76.0   \n",
      "2616                          72.0                          75.0   \n",
      "2617                          71.0                          73.0   \n",
      "2618                          72.0                          71.0   \n",
      "2619                          78.0                          78.0   \n",
      "2620                          72.0                          75.0   \n",
      "2621                          78.0                          74.0   \n",
      "2622                          72.0                          68.0   \n",
      "2623                          76.0                          71.0   \n",
      "2624                          67.0                          76.0   \n",
      "2625                          74.0                          72.0   \n",
      "2626                          72.0                          71.0   \n",
      "\n",
      "      home_player_4_overall_rating  ...  away_player_5_overall_rating  \\\n",
      "0                             67.0  ...                          66.0   \n",
      "1                             64.0  ...                          63.0   \n",
      "2                             66.0  ...                          64.0   \n",
      "3                             64.0  ...                          60.0   \n",
      "4                             73.0  ...                          60.0   \n",
      "5                             64.0  ...                          65.0   \n",
      "6                             70.0  ...                          69.0   \n",
      "7                             72.0  ...                          70.0   \n",
      "8                             62.0  ...                          73.0   \n",
      "9                             63.0  ...                          66.0   \n",
      "10                            68.0  ...                          65.0   \n",
      "11                            70.0  ...                          58.0   \n",
      "12                            69.0  ...                          69.0   \n",
      "13                            63.0  ...                          66.0   \n",
      "14                            72.0  ...                          63.0   \n",
      "15                            67.0  ...                          64.0   \n",
      "16                            66.0  ...                          64.0   \n",
      "17                            57.0  ...                          69.0   \n",
      "18                            63.0  ...                          66.0   \n",
      "19                            65.0  ...                          62.0   \n",
      "20                            66.0  ...                          67.0   \n",
      "21                            64.0  ...                          66.0   \n",
      "22                            73.0  ...                          69.0   \n",
      "23                            71.0  ...                          69.0   \n",
      "24                            66.0  ...                          64.0   \n",
      "25                            67.0  ...                          62.0   \n",
      "26                            60.0  ...                          71.0   \n",
      "27                            69.0  ...                          68.0   \n",
      "28                            67.0  ...                          64.0   \n",
      "29                            64.0  ...                          58.0   \n",
      "...                            ...  ...                           ...   \n",
      "2597                          73.0  ...                          60.0   \n",
      "2598                          79.0  ...                          79.0   \n",
      "2599                          73.0  ...                          72.0   \n",
      "2600                          75.0  ...                          74.0   \n",
      "2601                          75.0  ...                          76.0   \n",
      "2602                          68.0  ...                          73.0   \n",
      "2603                          69.0  ...                          75.0   \n",
      "2604                          69.0  ...                          76.0   \n",
      "2605                          75.0  ...                          83.0   \n",
      "2606                          71.0  ...                          72.0   \n",
      "2607                          78.0  ...                          74.0   \n",
      "2608                          75.0  ...                          72.0   \n",
      "2609                          75.0  ...                          79.0   \n",
      "2610                          75.0  ...                          62.0   \n",
      "2611                          78.0  ...                          72.0   \n",
      "2612                          74.0  ...                          73.0   \n",
      "2613                          72.0  ...                          69.0   \n",
      "2614                          76.0  ...                          69.0   \n",
      "2615                          85.0  ...                          72.0   \n",
      "2616                          72.0  ...                          81.0   \n",
      "2617                          78.0  ...                          75.0   \n",
      "2618                          73.0  ...                          72.0   \n",
      "2619                          79.0  ...                          69.0   \n",
      "2620                          73.0  ...                          76.0   \n",
      "2621                          81.0  ...                          73.0   \n",
      "2622                          75.0  ...                          75.0   \n",
      "2623                          74.0  ...                          76.0   \n",
      "2624                          69.0  ...                          82.0   \n",
      "2625                          69.0  ...                          68.0   \n",
      "2626                          72.0  ...                          81.0   \n",
      "\n",
      "      away_player_6_overall_rating  away_player_7_overall_rating  \\\n",
      "0                             69.0                          68.0   \n",
      "1                             66.0                          67.0   \n",
      "2                             62.0                          61.0   \n",
      "3                             63.0                          64.0   \n",
      "4                             61.0                          67.0   \n",
      "5                             71.0                          64.0   \n",
      "6                             72.0                          72.0   \n",
      "7                             69.0                          71.0   \n",
      "8                             68.0                          64.0   \n",
      "9                             68.0                          65.0   \n",
      "10                            57.0                          69.0   \n",
      "11                            61.0                          65.0   \n",
      "12                            65.0                          67.0   \n",
      "13                            64.0                          68.0   \n",
      "14                            66.0                          67.0   \n",
      "15                            63.0                          66.0   \n",
      "16                            66.0                          65.0   \n",
      "17                            67.0                          68.0   \n",
      "18                            74.0                          70.0   \n",
      "19                            63.0                          64.0   \n",
      "20                            69.0                          62.0   \n",
      "21                            64.0                          66.0   \n",
      "22                            70.0                          67.0   \n",
      "23                            64.0                          64.0   \n",
      "24                            69.0                          61.0   \n",
      "25                            68.0                          65.0   \n",
      "26                            71.0                          67.0   \n",
      "27                            68.0                          72.0   \n",
      "28                            63.0                          63.0   \n",
      "29                            73.0                          59.0   \n",
      "...                            ...                           ...   \n",
      "2597                          68.0                          77.0   \n",
      "2598                          75.0                          72.0   \n",
      "2599                          68.0                          73.0   \n",
      "2600                          74.0                          69.0   \n",
      "2601                          79.0                          82.0   \n",
      "2602                          75.0                          76.0   \n",
      "2603                          77.0                          74.0   \n",
      "2604                          85.0                          72.0   \n",
      "2605                          83.0                          87.0   \n",
      "2606                          76.0                          70.0   \n",
      "2607                          75.0                          74.0   \n",
      "2608                          69.0                          73.0   \n",
      "2609                          77.0                          78.0   \n",
      "2610                          72.0                          71.0   \n",
      "2611                          75.0                          77.0   \n",
      "2612                          74.0                          74.0   \n",
      "2613                          74.0                          73.0   \n",
      "2614                          72.0                          75.0   \n",
      "2615                          73.0                          69.0   \n",
      "2616                          90.0                          85.0   \n",
      "2617                          75.0                          72.0   \n",
      "2618                          68.0                          73.0   \n",
      "2619                          73.0                          74.0   \n",
      "2620                          76.0                          79.0   \n",
      "2621                          75.0                          72.0   \n",
      "2622                          74.0                          69.0   \n",
      "2623                          76.0                          78.0   \n",
      "2624                          86.0                          87.0   \n",
      "2625                          73.0                          70.0   \n",
      "2626                          90.0                          83.0   \n",
      "\n",
      "      away_player_8_overall_rating  away_player_9_overall_rating  \\\n",
      "0                             68.0                          72.0   \n",
      "1                             62.0                          65.0   \n",
      "2                             66.0                          65.0   \n",
      "3                             59.0                          61.0   \n",
      "4                             66.0                          61.0   \n",
      "5                             66.0                          70.0   \n",
      "6                             71.0                          66.0   \n",
      "7                             76.0                          73.0   \n",
      "8                             65.0                          66.0   \n",
      "9                             63.0                          64.0   \n",
      "10                            70.0                          64.0   \n",
      "11                            65.0                          63.0   \n",
      "12                            65.0                          66.0   \n",
      "13                            66.0                          69.0   \n",
      "14                            63.0                          64.0   \n",
      "15                            68.0                          66.0   \n",
      "16                            67.0                          63.0   \n",
      "17                            70.0                          68.0   \n",
      "18                            72.0                          68.0   \n",
      "19                            61.0                          63.0   \n",
      "20                            71.0                          70.0   \n",
      "21                            66.0                          71.0   \n",
      "22                            68.0                          67.0   \n",
      "23                            69.0                          70.0   \n",
      "24                            64.0                          68.0   \n",
      "25                            63.0                          62.0   \n",
      "26                            76.0                          70.0   \n",
      "27                            71.0                          72.0   \n",
      "28                            65.0                          65.0   \n",
      "29                            67.0                          61.0   \n",
      "...                            ...                           ...   \n",
      "2597                          71.0                          71.0   \n",
      "2598                          80.0                          79.0   \n",
      "2599                          77.0                          74.0   \n",
      "2600                          74.0                          74.0   \n",
      "2601                          82.0                          81.0   \n",
      "2602                          75.0                          75.0   \n",
      "2603                          71.0                          72.0   \n",
      "2604                          76.0                          71.0   \n",
      "2605                          86.0                          87.0   \n",
      "2606                          75.0                          76.0   \n",
      "2607                          71.0                          66.0   \n",
      "2608                          74.0                          75.0   \n",
      "2609                          79.0                          73.0   \n",
      "2610                          76.0                          72.0   \n",
      "2611                          78.0                          76.0   \n",
      "2612                          72.0                          77.0   \n",
      "2613                          70.0                          64.0   \n",
      "2614                          73.0                          74.0   \n",
      "2615                          72.0                          74.0   \n",
      "2616                          87.0                          76.0   \n",
      "2617                          73.0                          79.0   \n",
      "2618                          77.0                          77.0   \n",
      "2619                          69.0                          75.0   \n",
      "2620                          76.0                          82.0   \n",
      "2621                          76.0                          75.0   \n",
      "2622                          71.0                          72.0   \n",
      "2623                          85.0                          77.0   \n",
      "2624                          86.0                          87.0   \n",
      "2625                          75.0                          76.0   \n",
      "2626                          87.0                          84.0   \n",
      "\n",
      "      away_player_10_overall_rating  away_player_11_overall_rating  odds_home  \\\n",
      "0                              66.0                           63.0   0.379532   \n",
      "1                              62.0                           66.0   0.503166   \n",
      "2                              72.0                           70.0   0.530293   \n",
      "3                              64.0                           56.0   0.580711   \n",
      "4                              66.0                           63.0   0.695433   \n",
      "5                              69.0                           63.0   0.528996   \n",
      "6                              74.0                           72.0   0.513034   \n",
      "7                              71.0                           77.0   0.317485   \n",
      "8                              69.0                           70.0   0.306530   \n",
      "9                              67.0                           68.0   0.421907   \n",
      "10                             65.0                           69.0   0.500483   \n",
      "11                             65.0                           66.0   0.530533   \n",
      "12                             68.0                           66.0   0.436676   \n",
      "13                             69.0                           66.0   0.360443   \n",
      "14                             66.0                           63.0   0.708239   \n",
      "15                             68.0                           72.0   0.589772   \n",
      "16                             68.0                           66.0   0.574525   \n",
      "17                             67.0                           70.0   0.461741   \n",
      "18                             70.0                           72.0   0.230077   \n",
      "19                             64.0                           64.0   0.479478   \n",
      "20                             61.0                           67.0   0.327765   \n",
      "21                             68.0                           68.0   0.397069   \n",
      "22                             70.0                           68.0   0.579354   \n",
      "23                             72.0                           65.0   0.612398   \n",
      "24                             66.0                           69.0   0.573247   \n",
      "25                             68.0                           67.0   0.488724   \n",
      "26                             71.0                           74.0   0.150452   \n",
      "27                             74.0                           66.0   0.376904   \n",
      "28                             65.0                           65.0   0.501535   \n",
      "29                             67.0                           66.0   0.310981   \n",
      "...                             ...                            ...        ...   \n",
      "2597                           80.0                           70.0   0.475474   \n",
      "2598                           75.0                           75.0   0.524064   \n",
      "2599                           77.0                           77.0   0.468138   \n",
      "2600                           73.0                           71.0   0.490216   \n",
      "2601                           76.0                           84.0   0.282579   \n",
      "2602                           74.0                           75.0   0.398077   \n",
      "2603                           74.0                           74.0   0.499737   \n",
      "2604                           75.0                           82.0   0.343421   \n",
      "2605                           92.0                           87.0   0.489329   \n",
      "2606                           76.0                           73.0   0.407656   \n",
      "2607                           71.0                           75.0   0.476514   \n",
      "2608                           70.0                           64.0   0.577973   \n",
      "2609                           79.0                           88.0   0.274264   \n",
      "2610                           72.0                           73.0   0.455701   \n",
      "2611                           80.0                           77.0   0.547142   \n",
      "2612                           73.0                           75.0   0.490474   \n",
      "2613                           72.0                           75.0   0.470648   \n",
      "2614                           72.0                           74.0   0.558276   \n",
      "2615                           74.0                           73.0   0.791144   \n",
      "2616                           94.0                           85.0   0.125358   \n",
      "2617                           74.0                           75.0   0.333361   \n",
      "2618                           79.0                           72.0   0.439596   \n",
      "2619                           72.0                           73.0   0.677984   \n",
      "2620                           66.0                           84.0   0.326380   \n",
      "2621                           74.0                           75.0   0.489335   \n",
      "2622                           74.0                           74.0   0.459102   \n",
      "2623                           78.0                           82.0   0.308310   \n",
      "2624                           92.0                           85.0   0.132418   \n",
      "2625                           76.0                           73.0   0.472065   \n",
      "2626                           94.0                           85.0   0.111772   \n",
      "\n",
      "      odds_draw  odds_away  \n",
      "0      0.287801   0.332667  \n",
      "1      0.266833   0.230001  \n",
      "2      0.264442   0.205265  \n",
      "3      0.246617   0.172672  \n",
      "4      0.190179   0.114387  \n",
      "5      0.257922   0.213083  \n",
      "6      0.264641   0.222325  \n",
      "7      0.284919   0.397596  \n",
      "8      0.275446   0.418024  \n",
      "9      0.282571   0.295523  \n",
      "10     0.268463   0.231054  \n",
      "11     0.263674   0.205793  \n",
      "12     0.286004   0.277320  \n",
      "13     0.285124   0.354433  \n",
      "14     0.180079   0.111682  \n",
      "15     0.235849   0.174378  \n",
      "16     0.246108   0.179367  \n",
      "17     0.276432   0.261826  \n",
      "18     0.258630   0.511293  \n",
      "19     0.277517   0.243005  \n",
      "20     0.286286   0.385949  \n",
      "21     0.289102   0.313829  \n",
      "22     0.238552   0.182094  \n",
      "23     0.230612   0.156990  \n",
      "24     0.242175   0.184578  \n",
      "25     0.264865   0.246411  \n",
      "26     0.228655   0.620893  \n",
      "27     0.285637   0.337458  \n",
      "28     0.270450   0.228015  \n",
      "29     0.282116   0.406903  \n",
      "...         ...        ...  \n",
      "2597   0.279635   0.244890  \n",
      "2598   0.261579   0.214357  \n",
      "2599   0.281810   0.250053  \n",
      "2600   0.276936   0.232848  \n",
      "2601   0.288622   0.428799  \n",
      "2602   0.294981   0.306942  \n",
      "2603   0.277235   0.223029  \n",
      "2604   0.290918   0.365661  \n",
      "2605   0.256098   0.254573  \n",
      "2606   0.289455   0.302890  \n",
      "2607   0.271339   0.252147  \n",
      "2608   0.249798   0.172229  \n",
      "2609   0.281432   0.444304  \n",
      "2610   0.282776   0.261524  \n",
      "2611   0.254605   0.198253  \n",
      "2612   0.276187   0.233339  \n",
      "2613   0.288582   0.240769  \n",
      "2614   0.255030   0.186694  \n",
      "2615   0.127395   0.081461  \n",
      "2616   0.194487   0.680155  \n",
      "2617   0.292443   0.374195  \n",
      "2618   0.288140   0.272263  \n",
      "2619   0.201577   0.120439  \n",
      "2620   0.288065   0.385555  \n",
      "2621   0.273647   0.237018  \n",
      "2622   0.287852   0.253046  \n",
      "2623   0.295389   0.396301  \n",
      "2624   0.213579   0.654002  \n",
      "2625   0.277108   0.250827  \n",
      "2626   0.178452   0.709775  \n",
      "\n",
      "[2627 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Upload data\n",
    "\n",
    "labels = pd.read_csv(\"labels.csv\", names=[\"match\", \"label\"])\n",
    "labels = labels.replace({'Defeat': 0}, regex=True)\n",
    "labels = labels.replace({'Draw': 1}, regex=True)\n",
    "labels = labels.replace({'Win': 2}, regex=True)\n",
    "labels = labels.drop('match', axis=1)\n",
    "\n",
    "\n",
    "features = pd.read_csv(\"features.csv\")\n",
    "features.rename( columns={'Unnamed: 0':'match'}, inplace=True )\n",
    "features = features.drop('match', axis=1)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K cross fold validation\n",
    "\n",
    "To test how well our model is able to get trained by some data and then predict data it hasn't seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Train, Validation\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(labels['label'])\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "counter = 1\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    val = features.iloc[test_index, :]\n",
    "\n",
    "    train = features.iloc[train_index, :]\n",
    "    \n",
    "    val.to_csv(os.path.join('folds' + os.sep + 'validate', str(counter) + '.csv'))\n",
    "    train.to_csv(os.path.join('folds' + os.sep + 'train', str(counter) + '.csv'))\n",
    "    \n",
    "    val_target = labels.iloc[test_index, :]\n",
    "    train_target = labels.iloc[train_index, :]\n",
    "    val_target.to_csv(os.path.join('targets' + os.sep + 'validate', str(counter) + '.csv'))\n",
    "    train_target.to_csv(os.path.join('targets' + os.sep + 'train', str(counter) + '.csv'))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN Algorithm</h3>\n",
    "<p> K-nearest neighbors with an Euclidean distance measure is sensitive to magnitudes and hence should be scaled for all features to weigh in equally.</p>\n",
    "<p>The following one is with using 20% of the entries for test and the rest to train</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61 49 55]\n",
      " [54 29 54]\n",
      " [98 44 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.37      0.32       165\n",
      "           1       0.24      0.21      0.22       137\n",
      "           2       0.43      0.37      0.40       224\n",
      "\n",
      "    accuracy                           0.33       526\n",
      "   macro avg       0.32      0.32      0.31       526\n",
      "weighted avg       0.33      0.33      0.33       526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X1_train)\n",
    "\n",
    "X1_train = scaler.transform(X1_train)\n",
    "X1_test = scaler.transform(X1_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, Y1_train)\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "print(confusion_matrix(Y1_test, y1_pred))\n",
    "print(classification_report(Y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Using k-fold cross validation:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43155894 0.42585551 0.46666667 0.41333333 0.43809524]\n",
      "cv_scores mean:0.4351019373528879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=5)\n",
    "cv_scores = cross_val_score(knn_cv, features, labels, cv=5)\n",
    "print(cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "knn2 = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "knn_gscv.fit(features, labels)\n",
    "#knn_gscv.best_params_\n",
    "knn_gscv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We should test different K values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nerror_rate = []\\nfor i in range(1,40):\\n\\n    knn = KNeighborsClassifier(n_neighbors=i)\\n    knn.fit(X_train,Y_train)\\n    pred_i = knn.predict(X_test)\\n    error_rate.append(np.mean(pred_i != Y_test))\\n    \\nplt.figure(figsize=(12, 6))\\nplt.plot(range(1, 40), error_rate, color='red', linestyle='dashed', marker='o',\\n         markerfacecolor='blue', markersize=10)\\nplt.title('Error Rate K Value')\\nplt.xlabel('K Value')\\nplt.ylabel('Mean Error')\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "error_rate = []\n",
    "for i in range(1,40):\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,Y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != Y_test))\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error_rate, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-e7adb391c643>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-e7adb391c643>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    8, activation=\"relu\", input_shape=(features.shape[-1], kernel_initializer=\"he_uniform\")\u001b[0m\n\u001b[1;37m                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            8, activation=\"relu\", input_shape=(features.shape[-1])\n",
    "        ),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(8, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(8, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2101, 31)\n",
      "(2101, 3)\n",
      "Train on 2101 samples, validate on 526 samples\n",
      "Epoch 1/30\n",
      "2101/2101 [==============================] - 1s 252us/sample - loss: 2.0357 - acc: 0.4241 - val_loss: 1.0906 - val_acc: 0.4430\n",
      "Epoch 2/30\n",
      "2101/2101 [==============================] - 0s 52us/sample - loss: 1.1365 - acc: 0.4260 - val_loss: 1.0723 - val_acc: 0.4430\n",
      "Epoch 3/30\n",
      "2101/2101 [==============================] - 0s 51us/sample - loss: 1.0995 - acc: 0.4407 - val_loss: 1.0863 - val_acc: 0.4430\n",
      "Epoch 4/30\n",
      "2101/2101 [==============================] - 0s 49us/sample - loss: 1.1017 - acc: 0.4422 - val_loss: 1.3674 - val_acc: 0.3821\n",
      "Epoch 5/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.1354 - acc: 0.4360 - val_loss: 1.0971 - val_acc: 0.4430\n",
      "Epoch 6/30\n",
      "2101/2101 [==============================] - 0s 45us/sample - loss: 1.1415 - acc: 0.4393 - val_loss: 1.0928 - val_acc: 0.4430\n",
      "Epoch 7/30\n",
      "2101/2101 [==============================] - 0s 43us/sample - loss: 1.1139 - acc: 0.4346 - val_loss: 1.0784 - val_acc: 0.4430\n",
      "Epoch 8/30\n",
      "2101/2101 [==============================] - 0s 45us/sample - loss: 1.1205 - acc: 0.4365 - val_loss: 1.0810 - val_acc: 0.4430\n",
      "Epoch 9/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.0815 - acc: 0.4369 - val_loss: 1.0764 - val_acc: 0.4430\n",
      "Epoch 10/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.0793 - acc: 0.4412 - val_loss: 1.0767 - val_acc: 0.4430\n",
      "Epoch 11/30\n",
      "2101/2101 [==============================] - 0s 43us/sample - loss: 1.0837 - acc: 0.4431 - val_loss: 1.0730 - val_acc: 0.4430\n",
      "Epoch 12/30\n",
      "2101/2101 [==============================] - 0s 44us/sample - loss: 1.1123 - acc: 0.4350 - val_loss: 1.0994 - val_acc: 0.2605\n",
      "Epoch 13/30\n",
      "2101/2101 [==============================] - 0s 42us/sample - loss: 1.0813 - acc: 0.4417 - val_loss: 1.0736 - val_acc: 0.4430\n",
      "Epoch 14/30\n",
      "2101/2101 [==============================] - 0s 44us/sample - loss: 1.0768 - acc: 0.4398 - val_loss: 1.0718 - val_acc: 0.4430\n",
      "Epoch 15/30\n",
      "2101/2101 [==============================] - 0s 41us/sample - loss: 1.0804 - acc: 0.4436 - val_loss: 1.0828 - val_acc: 0.4430\n",
      "Epoch 16/30\n",
      "2101/2101 [==============================] - 0s 44us/sample - loss: 1.0777 - acc: 0.4412 - val_loss: 1.1203 - val_acc: 0.4430\n",
      "Epoch 17/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.0800 - acc: 0.4407 - val_loss: 1.0720 - val_acc: 0.4430\n",
      "Epoch 18/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.0777 - acc: 0.4350 - val_loss: 1.0763 - val_acc: 0.4430\n",
      "Epoch 19/30\n",
      "2101/2101 [==============================] - 0s 42us/sample - loss: 1.0787 - acc: 0.4436 - val_loss: 1.0831 - val_acc: 0.4430\n",
      "Epoch 20/30\n",
      "2101/2101 [==============================] - 0s 43us/sample - loss: 1.0741 - acc: 0.4388 - val_loss: 1.0786 - val_acc: 0.4430\n",
      "Epoch 21/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.0776 - acc: 0.4379 - val_loss: 1.0725 - val_acc: 0.4430\n",
      "Epoch 22/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.0802 - acc: 0.4398 - val_loss: 1.0804 - val_acc: 0.4430\n",
      "Epoch 23/30\n",
      "2101/2101 [==============================] - 0s 45us/sample - loss: 1.0745 - acc: 0.4446 - val_loss: 1.0720 - val_acc: 0.4430\n",
      "Epoch 24/30\n",
      "2101/2101 [==============================] - 0s 40us/sample - loss: 1.0789 - acc: 0.4365 - val_loss: 1.0735 - val_acc: 0.4430\n",
      "Epoch 25/30\n",
      "2101/2101 [==============================] - 0s 40us/sample - loss: 1.0774 - acc: 0.4374 - val_loss: 1.0753 - val_acc: 0.4430\n",
      "Epoch 26/30\n",
      "2101/2101 [==============================] - 0s 42us/sample - loss: 1.0793 - acc: 0.4436 - val_loss: 1.0729 - val_acc: 0.4430\n",
      "Epoch 27/30\n",
      "2101/2101 [==============================] - 0s 45us/sample - loss: 1.0795 - acc: 0.4422 - val_loss: 1.0840 - val_acc: 0.4430\n",
      "Epoch 28/30\n",
      "2101/2101 [==============================] - 0s 44us/sample - loss: 1.0789 - acc: 0.4436 - val_loss: 1.0744 - val_acc: 0.4430\n",
      "Epoch 29/30\n",
      "2101/2101 [==============================] - 0s 42us/sample - loss: 1.0757 - acc: 0.4412 - val_loss: 1.0774 - val_acc: 0.4430\n",
      "Epoch 30/30\n",
      "2101/2101 [==============================] - 0s 46us/sample - loss: 1.0777 - acc: 0.4331 - val_loss: 1.0799 - val_acc: 0.4430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24173891f98>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = \"1\"\n",
    "\n",
    "train_features = pd.read_csv(os.path.join('folds' + os.sep + 'train', fold + '.csv')).drop('Unnamed: 0', axis=1)\n",
    "train_targets = to_categorical(pd.read_csv(os.path.join('targets' + os.sep + 'train', fold + '.csv')).drop('Unnamed: 0', axis=1))\n",
    "val_features = pd.read_csv(os.path.join('folds' + os.sep + 'validate', fold + '.csv')).drop('Unnamed: 0', axis=1)\n",
    "val_targets = to_categorical(pd.read_csv(os.path.join('targets' + os.sep + 'validate', fold + '.csv')).drop('Unnamed: 0', axis=1))\n",
    "\n",
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "opt = RMSprop(\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "   loss='categorical_crossentropy', optimizer=opt, metrics=['acc']\n",
    ")\n",
    "\n",
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_targets.shape)\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_data=(val_features, val_targets),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
