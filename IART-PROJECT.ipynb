{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Importing required libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_label(match):\n",
    "    ''' Derives a label for a given match. '''\n",
    "    \n",
    "    #Define variables\n",
    "    home_goals = match['home_team_goal']\n",
    "    away_goals = match['away_team_goal']\n",
    "     \n",
    "    label = pd.DataFrame()\n",
    "    label.loc[0,'match_api_id'] = match['match_api_id'] \n",
    "\n",
    "    #Identify match label  \n",
    "    if home_goals > away_goals:\n",
    "        label.loc[0,'label'] = \"Win\"\n",
    "    if home_goals == away_goals:\n",
    "        label.loc[0,'label'] = \"Draw\"\n",
    "    if home_goals < away_goals:\n",
    "        label.loc[0,'label'] = \"Defeat\"\n",
    "\n",
    "    #Return label        \n",
    "    return label.loc[0]\n",
    "    \n",
    "def get_fifa_stats(match, player_stats):\n",
    "    ''' Aggregates fifa stats for a given match. '''    \n",
    "    \n",
    "    #Define variables\n",
    "    match_id =  match.match_api_id\n",
    "    date = match['date']\n",
    "    players = ['home_player_1', 'home_player_2', 'home_player_3', \"home_player_4\", \"home_player_5\",\n",
    "               \"home_player_6\", \"home_player_7\", \"home_player_8\", \"home_player_9\", \"home_player_10\",\n",
    "               \"home_player_11\", \"away_player_1\", \"away_player_2\", \"away_player_3\", \"away_player_4\",\n",
    "               \"away_player_5\", \"away_player_6\", \"away_player_7\", \"away_player_8\", \"away_player_9\",\n",
    "               \"away_player_10\", \"away_player_11\"]\n",
    "    player_stats_new = pd.DataFrame()\n",
    "    names = []\n",
    "    \n",
    "    #Loop through all players\n",
    "    for player in players:   \n",
    "            \n",
    "        #Get player ID\n",
    "        player_id = match[player]\n",
    "        \n",
    "        #Get player stats \n",
    "        stats = player_stats[player_stats.player_api_id == player_id]\n",
    "            \n",
    "        #Identify current stats       \n",
    "        current_stats = stats[stats.date < date].sort_values(by = 'date', ascending = False)[:1]\n",
    "        \n",
    "        if np.isnan(player_id) == True:\n",
    "            overall_rating = pd.Series(0)\n",
    "        else:\n",
    "            current_stats.reset_index(inplace = True, drop = True)\n",
    "            overall_rating = pd.Series(current_stats.loc[0, \"overall_rating\"])\n",
    "\n",
    "        #Rename stat\n",
    "        name = \"{}_overall_rating\".format(player)\n",
    "        names.append(name)\n",
    "            \n",
    "        #Aggregate stats\n",
    "        player_stats_new = pd.concat([player_stats_new, overall_rating], axis = 1)\n",
    "    \n",
    "    player_stats_new.columns = names        \n",
    "    player_stats_new['match_api_id'] = match_id\n",
    "\n",
    "    player_stats_new.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    #Return player stats    \n",
    "    return player_stats_new.iloc[0]     \n",
    "      \n",
    "def get_fifa_data(matches, player_stats, path = None, data_exists = False):\n",
    "    ''' Gets fifa data for all matches. '''  \n",
    "    \n",
    "    #Check if fifa data already exists\n",
    "    if data_exists == True:\n",
    "        \n",
    "        fifa_data = pd.read_pickle(path)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Collecting fifa data for each match...\")       \n",
    "        start = time()\n",
    "        \n",
    "        #Apply get_fifa_stats for each match\n",
    "        fifa_data = matches.apply(lambda x :get_fifa_stats(x, player_stats), axis = 1)\n",
    "        \n",
    "        end = time()    \n",
    "        print(\"Fifa data collected in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    #Return fifa_data\n",
    "    return fifa_data\n",
    "\n",
    "def get_overall_fifa_rankings(fifa, get_overall = False):\n",
    "    ''' Get overall fifa rankings from fifa data. '''\n",
    "      \n",
    "    temp_data = fifa\n",
    "    \n",
    "    #Check if only overall player stats are desired\n",
    "    if get_overall == True:\n",
    "        \n",
    "        #Get overall stats\n",
    "        data = temp_data.loc[:,(fifa.columns.str.contains('overall_rating'))]\n",
    "        data.loc[:,'match_api_id'] = temp_data.loc[:,'match_api_id']\n",
    "    else:\n",
    "        #Get all stats except for stat date\n",
    "        cols = fifa.loc[:,(fifa.columns.str.contains('date_stat'))]\n",
    "        temp_data = fifa.drop(cols.columns, axis = 1)        \n",
    "        data = temp_data\n",
    "    \n",
    "    #Return data\n",
    "    return data\n",
    "\n",
    "def get_last_matches(matches, date, team, x = 10):\n",
    "    ''' Get the last x matches of a given team. '''\n",
    "    \n",
    "    #Filter team matches from matches\n",
    "    team_matches = matches[(matches['home_team_api_id'] == team) | (matches['away_team_api_id'] == team)]\n",
    "                           \n",
    "    #Filter x last matches from team matches\n",
    "    last_matches = team_matches[team_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    \n",
    "    #Return last matches\n",
    "    return last_matches\n",
    "    \n",
    "def get_last_matches_against_eachother(matches, date, home_team, away_team, x = 10):\n",
    "    ''' Get the last x matches of two given teams. '''\n",
    "    \n",
    "    #Find matches of both teams\n",
    "    home_matches = matches[(matches['home_team_api_id'] == home_team) & (matches['away_team_api_id'] == away_team)]    \n",
    "    away_matches = matches[(matches['home_team_api_id'] == away_team) & (matches['away_team_api_id'] == home_team)]  \n",
    "    total_matches = pd.concat([home_matches, away_matches])\n",
    "    \n",
    "    #Get last x matches\n",
    "    try:    \n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:x,:]\n",
    "    except:\n",
    "        last_matches = total_matches[total_matches.date < date].sort_values(by = 'date', ascending = False).iloc[0:total_matches.shape[0],:]\n",
    "        \n",
    "        #Check for error in data\n",
    "        if(last_matches.shape[0] > x):\n",
    "            print(\"Error in obtaining matches\")\n",
    "            \n",
    "    #Return data\n",
    "    return last_matches\n",
    "    \n",
    "def get_goals(matches, team):\n",
    "    ''' Get the goals of a specfic team from a set of matches. '''\n",
    "    \n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.home_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.away_team_api_id == team].sum())\n",
    "\n",
    "    total_goals = home_goals + away_goals\n",
    "    \n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "\n",
    "def get_goals_conceided(matches, team):\n",
    "    ''' Get the goals conceided of a specfic team from a set of matches. '''\n",
    "\n",
    "    #Find home and away goals\n",
    "    home_goals = int(matches.home_team_goal[matches.away_team_api_id == team].sum())\n",
    "    away_goals = int(matches.away_team_goal[matches.home_team_api_id == team].sum())\n",
    "\n",
    "    total_goals = home_goals + away_goals\n",
    "\n",
    "    #Return total goals\n",
    "    return total_goals\n",
    "\n",
    "def get_wins(matches, team):\n",
    "    ''' Get the number of wins of a specfic team from a set of matches. '''\n",
    "    \n",
    "    #Find home and away wins\n",
    "    home_wins = int(matches.home_team_goal[(matches.home_team_api_id == team) & (matches.home_team_goal > matches.away_team_goal)].count())\n",
    "    away_wins = int(matches.away_team_goal[(matches.away_team_api_id == team) & (matches.away_team_goal > matches.home_team_goal)].count())\n",
    "\n",
    "    total_wins = home_wins + away_wins\n",
    "\n",
    "    #Return total wins\n",
    "    return total_wins      \n",
    "    \n",
    "def get_match_features(match, matches, x = 10):\n",
    "    ''' Create match specific features for a given match. '''\n",
    "    \n",
    "    #Define variables\n",
    "    date = match.date\n",
    "    home_team = match.home_team_api_id\n",
    "    away_team = match.away_team_api_id\n",
    "    \n",
    "    #Get last x matches of home and away team\n",
    "    matches_home_team = get_last_matches(matches, date, home_team, x = 10)\n",
    "    matches_away_team = get_last_matches(matches, date, away_team, x = 10)\n",
    "    \n",
    "    #Get last x matches of both teams against each other\n",
    "    last_matches_against = get_last_matches_against_eachother(matches, date, home_team, away_team, x = 3)\n",
    "    \n",
    "    #Create goal variables\n",
    "    home_goals = get_goals(matches_home_team, home_team)\n",
    "    away_goals = get_goals(matches_away_team, away_team)\n",
    "    home_goals_conceided = get_goals_conceided(matches_home_team, home_team)\n",
    "    away_goals_conceided = get_goals_conceided(matches_away_team, away_team)\n",
    "    \n",
    "    #Define result data frame\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    #Define ID features\n",
    "    result.loc[0, 'match_api_id'] = match.match_api_id\n",
    "    result.loc[0, 'league_id'] = match.league_id\n",
    "\n",
    "    #Create match features\n",
    "    result.loc[0, 'home_team_goals_difference'] = home_goals - home_goals_conceided\n",
    "    result.loc[0, 'away_team_goals_difference'] = away_goals - away_goals_conceided\n",
    "    result.loc[0, 'games_won_home_team'] = get_wins(matches_home_team, home_team) \n",
    "    result.loc[0, 'games_won_away_team'] = get_wins(matches_away_team, away_team)\n",
    "    result.loc[0, 'games_against_home'] = get_wins(last_matches_against, home_team)\n",
    "    result.loc[0, 'games_against_away'] = get_wins(last_matches_against, away_team)\n",
    "    \n",
    "    #Return match features\n",
    "    return result.loc[0]\n",
    "    \n",
    "def create_feables(matches, fifa, bookkeepers, get_overall = False, horizontal = True, x = 10, verbose = True):\n",
    "    ''' Create and aggregate features and labels for all matches. '''\n",
    "\n",
    "\n",
    "    #Get fifa stats features\n",
    "    fifa_stats = get_overall_fifa_rankings(fifa, get_overall)\n",
    "\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Generating match features...\")\n",
    "    start = time()\n",
    "    \n",
    "    #Get match features for all matches\n",
    "    match_stats = matches.apply(lambda x: get_match_features(x, matches, x = 10), axis = 1)\n",
    "    #Create dummies for league ID feature\n",
    "    dummies = pd.get_dummies(match_stats['league_id']).rename(columns = lambda x: 'League_' + str(x))\n",
    "    match_stats = pd.concat([match_stats, dummies], axis = 1)\n",
    "    match_stats.drop(['league_id'], inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match features generated in {:.1f} minutes\".format((end - start)/60))\n",
    "    \n",
    "    if verbose == True:    \n",
    "        print(\"Generating match labels...\")\n",
    "    start = time()\n",
    "    \n",
    "    #Create match labels\n",
    "    labels = matches.apply(get_match_label, axis = 1)\n",
    "    \n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Match labels generated in {:.1f} minutes\".format((end - start)/60))\n",
    "        \n",
    "    #Get bookkeeper quotas for all matches\n",
    "    bk_data = get_bookkeeper_data(matches, bookkeepers, horizontal = True)\n",
    "    bk_data.loc[:,'match_api_id'] = matches.loc[:,'match_api_id']\n",
    "    end = time()\n",
    "    if verbose == True:\n",
    "        print(\"Bookkeeper data generated in {:.1f} minutes\".format((end - start)/60))\n",
    "\n",
    "    \n",
    "    #Merges features and labels into one frame\n",
    "    features = pd.merge(match_stats, fifa_stats, on = 'match_api_id', how = 'left')\n",
    "    features = pd.merge(features, bk_data, on = 'match_api_id', how = 'left')\n",
    "    feables = pd.merge(features, labels, on = 'match_api_id', how = 'left')\n",
    "    \n",
    "    #Drop NA values\n",
    "    feables.dropna(inplace = True)\n",
    "\n",
    "    #Return preprocessed data\n",
    "    return feables\n",
    "    \n",
    "def train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs, use_grid_search = True, \n",
    "                     best_components = None, best_params = None):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    #Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    \n",
    "    #Check if grid search should be applied\n",
    "    if use_grid_search == True: \n",
    "        \n",
    "        #Define pipeline of dm reduction and classifier\n",
    "        estimators = [('dm_reduce', dm_reduction), ('clf', clf)]\n",
    "        pipeline = Pipeline(estimators)\n",
    "        \n",
    "        #Grid search over pipeline and return best classifier\n",
    "        grid_obj = model_selection.GridSearchCV(pipeline, param_grid = params, scoring = scorer, cv = cv_sets, n_jobs = jobs)\n",
    "        grid_obj.fit(X_train, y_train)\n",
    "        best_pipe = grid_obj.best_estimator_\n",
    "    else:\n",
    "        \n",
    "        #Use best components that are known without grid search        \n",
    "        estimators = [('dm_reduce', dm_reduction(n_components = best_components)), ('clf', clf(best_params))]\n",
    "        pipeline = Pipeline(estimators)        \n",
    "        best_pipe = pipeline.fit(X_train, y_train)\n",
    "        \n",
    "    end = time()\n",
    "    \n",
    "    #Print the results\n",
    "    print(\"Trained {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "    \n",
    "    #Return best pipe\n",
    "    return best_pipe\n",
    "    \n",
    "def predict_labels(clf, best_pipe, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on scorer. '''\n",
    "    \n",
    "    #Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(best_pipe.named_steps['dm_reduce'].transform(features))\n",
    "    end = time()\n",
    "    \n",
    "    #Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds\".format(end - start))\n",
    "    return accuracy_score(target.values, y_pred)\n",
    "    \n",
    "def train_calibrate_predict(clf, dm_reduction, X_train, y_train, X_calibrate, y_calibrate, X_test, y_test, cv_sets, params, scorer, jobs, \n",
    "                            use_grid_search = True, **kwargs):\n",
    "    ''' Train and predict using a classifer based on scorer. '''\n",
    "    \n",
    "    #Indicate the classifier and the training set size\n",
    "    print(\"Training a {} with {}...\".format(clf.__class__.__name__, dm_reduction.__class__.__name__))\n",
    "    \n",
    "    #Train the classifier\n",
    "    best_pipe = train_classifier(clf, dm_reduction, X_train, y_train, cv_sets, params, scorer, jobs)\n",
    "    \n",
    "    #Calibrate classifier\n",
    "    print(\"Calibrating probabilities of classifier...\")\n",
    "    start = time()    \n",
    "    clf = CalibratedClassifierCV(best_pipe.named_steps['clf'], cv= 'prefit', method='isotonic')\n",
    "    clf.fit(best_pipe.named_steps['dm_reduce'].transform(X_calibrate), y_calibrate)\n",
    "    end = time()\n",
    "    print(\"Calibrated {} in {:.1f} minutes\".format(clf.__class__.__name__, (end - start)/60))\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"Score of {} for training set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_train, y_train)))\n",
    "    print(\"Score of {} for test set: {:.4f}.\".format(clf.__class__.__name__, predict_labels(clf, best_pipe, X_test, y_test)))\n",
    "    \n",
    "    #Return classifier, dm reduction, and label predictions for train and test set\n",
    "    return clf, best_pipe.named_steps['dm_reduce'], predict_labels(clf, best_pipe, X_train, y_train), predict_labels(clf, best_pipe, X_test, y_test)\n",
    "        \n",
    "def convert_odds_to_prob(match_odds):\n",
    "    ''' Converts bookkeeper odds to probabilities. '''\n",
    "    \n",
    "    #Define variables\n",
    "    match_id = match_odds.loc[:,'match_api_id']\n",
    "    bookkeeper = match_odds.loc[:,'bookkeeper']    \n",
    "    win_odd = match_odds.loc[:,'Win']\n",
    "    draw_odd = match_odds.loc[:,'Draw']\n",
    "    loss_odd = match_odds.loc[:,'Defeat']\n",
    "    \n",
    "    #Converts odds to prob\n",
    "    win_prob = 1 / win_odd\n",
    "    draw_prob = 1 / draw_odd\n",
    "    loss_prob = 1 / loss_odd\n",
    "    \n",
    "    total_prob = win_prob + draw_prob + loss_prob\n",
    "    \n",
    "    probs = pd.DataFrame()\n",
    "    \n",
    "    #Define output format and scale probs by sum over all probs\n",
    "    probs.loc[:,'match_api_id'] = match_id\n",
    "    probs.loc[:,'bookkeeper'] = bookkeeper\n",
    "    probs.loc[:,'Win'] = win_prob / total_prob\n",
    "    probs.loc[:,'Draw'] = draw_prob / total_prob\n",
    "    probs.loc[:,'Defeat'] = loss_prob / total_prob\n",
    "    \n",
    "    #Return probs and meta data\n",
    "    return probs\n",
    "    \n",
    "def get_bookkeeper_data(matches, bookkeepers, horizontal = True):\n",
    "    ''' Aggregates bookkeeper data for all matches and bookkeepers. '''\n",
    "    \n",
    "    bk_data = pd.DataFrame()\n",
    "    \n",
    "    #Loop through bookkeepers\n",
    "    for bookkeeper in bookkeepers:\n",
    "\n",
    "        #Find columns containing data of bookkeeper\n",
    "        temp_data = matches.loc[:,(matches.columns.str.contains(bookkeeper))]\n",
    "        temp_data.loc[:, 'bookkeeper'] = str(bookkeeper)\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "        \n",
    "        #Rename odds columns and convert to numeric\n",
    "        cols = temp_data.columns.values\n",
    "        cols[:3] = ['Win','Draw','Defeat']\n",
    "        temp_data.columns = cols\n",
    "        temp_data.loc[:,'Win'] = pd.to_numeric(temp_data['Win'])\n",
    "        temp_data.loc[:,'Draw'] = pd.to_numeric(temp_data['Draw'])\n",
    "        temp_data.loc[:,'Defeat'] = pd.to_numeric(temp_data['Defeat'])\n",
    "        \n",
    "        #Check if data should be aggregated horizontally\n",
    "        if(horizontal == True):\n",
    "            \n",
    "            #Convert data to probs\n",
    "            temp_data = convert_odds_to_prob(temp_data)\n",
    "            temp_data.drop('match_api_id', axis = 1, inplace = True)\n",
    "            temp_data.drop('bookkeeper', axis = 1, inplace = True)\n",
    "            \n",
    "            #Rename columns with bookkeeper names\n",
    "            win_name = bookkeeper + \"_\" + \"Win\"\n",
    "            draw_name = bookkeeper + \"_\" + \"Draw\"\n",
    "            defeat_name = bookkeeper + \"_\" + \"Defeat\"\n",
    "            temp_data.columns.values[:3] = [win_name, draw_name, defeat_name]\n",
    "\n",
    "            #Aggregate data\n",
    "            bk_data = pd.concat([bk_data, temp_data], axis = 1)\n",
    "        else:\n",
    "            #Aggregate vertically\n",
    "            bk_data = bk_data.append(temp_data, ignore_index = True)\n",
    "    \n",
    "    #If horizontal add match api id to data\n",
    "    if(horizontal == True):\n",
    "        temp_data.loc[:, 'match_api_id'] = matches.loc[:, 'match_api_id']\n",
    "    \n",
    "    #Return bookkeeper data\n",
    "    return bk_data\n",
    "    \n",
    "def get_bookkeeper_probs(matches, bookkeepers, horizontal = False):\n",
    "    ''' Get bookkeeper data and convert to probabilities for vertical aggregation. '''\n",
    "    \n",
    "    #Get bookkeeper data\n",
    "    data = get_bookkeeper_data(matches, bookkeepers, horizontal = False)\n",
    "    \n",
    "    #Convert odds to probabilities\n",
    "    probs = convert_odds_to_prob(data)\n",
    "    \n",
    "    #Return data\n",
    "    return probs\n",
    "\n",
    "def plot_confusion_matrix(y_test, X_test, clf, dim_reduce, path, cmap=plt.cm.Blues, normalize = False):    \n",
    "    ''' Plot confusion matrix for given classifier and data. '''\n",
    "    \n",
    "    #Define label names and get confusion matrix values\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, clf.predict(dim_reduce.transform(X_test)), labels)\n",
    "    \n",
    "    #Check if matrix should be normalized\n",
    "    if normalize == True:\n",
    "        \n",
    "        #Normalize\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Configure figure\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title= \"Confusion matrix of a {} with {}\".format(best_clf.base_estimator.__class__.__name__, best_dm_reduce.__class__.__name__)   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report\n",
    "    y_pred = clf.predict(dim_reduce.transform(X_test))\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "\n",
    "def compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False):\n",
    "    ''' Map bookkeeper and model probabilities. '''\n",
    "    \n",
    "    #Create features and labels for given matches\n",
    "    feables = create_feables(matches, fifa_data, bk, get_overall = True, verbose = False)\n",
    "    \n",
    "    #Ensure consistency\n",
    "    match_ids = list(feables['match_api_id'])\n",
    "    matches = matches[matches['match_api_id'].isin(match_ids)]\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Obtaining bookkeeper probabilities...\")\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    inputs = feables.drop('match_api_id', axis = 1)\n",
    "    labels = inputs.loc[:,'label']\n",
    "    features = inputs.drop('label', axis = 1)\n",
    "    \n",
    "    #Get model probabilities\n",
    "    if verbose == True:\n",
    "        print(\"Predicting probabilities based on model...\")\n",
    "    model_probs = pd.DataFrame()\n",
    "    label_table = pd.Series()\n",
    "    temp_probs = pd.DataFrame(clf.predict_proba(dim_reduce.transform(features)), columns = ['win_prob', 'draw_prob', 'defeat_prob'])\n",
    "    for bookkeeper in bookkeepers:\n",
    "        model_probs = model_probs.append(temp_probs, ignore_index = True)\n",
    "        label_table = label_table.append(labels)\n",
    "    model_probs.reset_index(inplace = True, drop = True)\n",
    "    label_table.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs['win_prob'] = model_probs['win_prob']\n",
    "    bookkeeper_probs['draw_prob'] = model_probs['draw_prob']\n",
    "    bookkeeper_probs['defeat_prob'] = model_probs['defeat_prob']\n",
    "    bookkeeper_probs['label'] = label_table \n",
    "    \n",
    "    #Aggregate win probabilities for each match\n",
    "    wins = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Win', 'win_prob', 'label']]\n",
    "    wins.loc[:, 'bet'] = 'Win'\n",
    "    wins = wins.rename(columns = {'Win':'bookkeeper_prob',\n",
    "                                  'win_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate draw probabilities for each match\n",
    "    draws = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Draw', 'draw_prob', 'label']]\n",
    "    draws.loc[:, 'bet'] = 'Draw'\n",
    "    draws = draws.rename(columns = {'Draw':'bookkeeper_prob',\n",
    "                                  'draw_prob': 'model_prob'})\n",
    "                                  \n",
    "    #Aggregate defeat probabilities for each match\n",
    "    defeats = bookkeeper_probs[['bookkeeper', 'match_api_id', 'Defeat', 'defeat_prob', 'label']]\n",
    "    defeats.loc[:, 'bet'] = 'Defeat'\n",
    "    defeats = defeats.rename(columns = {'Defeat':'bookkeeper_prob',\n",
    "                                  'defeat_prob': 'model_prob'})\n",
    "    \n",
    "    total = pd.concat([wins, draws, defeats])\n",
    "    \n",
    "    #Return total\n",
    "    return total\n",
    "    \n",
    "def find_good_bets(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, percentile, prob_cap, verbose = False):\n",
    "    ''' Find good bets for a given classifier and matches. '''\n",
    "    \n",
    "    #Compare model and classifier probabilities\n",
    "    probs = compare_probabilities(clf, dim_reduce, bk, bookkeepers, matches, fifa_data, verbose = False)\n",
    "    probs.loc[:, 'prob_difference'] = probs.loc[:,\"model_prob\"] - probs.loc[:,\"bookkeeper_prob\"]\n",
    "    \n",
    "    #Sort by createst difference to identify most underestimated bets    \n",
    "    values = probs['prob_difference']\n",
    "    values = values.sort_values(ascending = False)\n",
    "    values.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Selecting attractive bets...\")\n",
    "        \n",
    "    #Identify choices that fulfill requirements such as positive difference, minimum probability and match outcome\n",
    "    relevant_choices = probs[(probs.prob_difference > 0) & (probs.model_prob > prob_cap) & (probs.bet != \"Draw\")]\n",
    "    \n",
    "    #Select given percentile of relevant choices    \n",
    "    top_percent = 1 - percentile\n",
    "    choices = relevant_choices[relevant_choices.prob_difference >= relevant_choices.prob_difference.quantile(top_percent)]\n",
    "    choices.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    #Return choices\n",
    "    return choices\n",
    "\n",
    "def get_reward(choice, matches):\n",
    "    ''' Get the reward of a given bet. '''\n",
    "    \n",
    "    #Identify bet\n",
    "    match = matches[matches.match_api_id == choice.match_api_id]\n",
    "    bet_data = match.loc[:,(match.columns.str.contains(choice.bookkeeper))]\n",
    "    cols = bet_data.columns.values\n",
    "    cols[:3] = ['win','draw','defeat']\n",
    "    bet_data.columns = cols\n",
    "    \n",
    "    #Identfiy bet type and get quota\n",
    "    if choice.bet == 'Win':\n",
    "        bet_quota = bet_data.win.values\n",
    "    elif choice.bet == 'Draw':\n",
    "        bet_quota = bet_data.draw.values\n",
    "    elif choice.bet == 'Defeat':\n",
    "        bet_quota = bet_data.defeat.values\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    \n",
    "    #Check label and compute reward\n",
    "    if choice.bet == choice.label:\n",
    "        reward = bet_quota\n",
    "    else:\n",
    "        reward = 0\n",
    "    \n",
    "    #Return reward\n",
    "    return reward\n",
    "      \n",
    "def execute_bets(bet_choices, matches, verbose = False):\n",
    "    ''' Get rewards for all bets. '''    \n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Obtaining reward for chosen bets...\")\n",
    "    total_reward = 0\n",
    "    total_invested = 0\n",
    "    \n",
    "    #Loop through bets\n",
    "    loops = np.arange(0, bet_choices.shape[0])     \n",
    "    for i in loops:\n",
    "        \n",
    "        #Get rewards and accumulate profit\n",
    "        reward = get_reward(bet_choices.iloc[i,:], matches)\n",
    "        total_reward = total_reward + reward\n",
    "        total_invested += 1\n",
    "    \n",
    "    #Compute investment return\n",
    "    investment_return = float(total_reward / total_invested) - 1\n",
    "    \n",
    "    #Return investment return\n",
    "    return investment_return\n",
    "    \n",
    "def explore_data(features, inputs, path):\n",
    "    ''' Explore data by plotting KDE graphs. '''\n",
    "    \n",
    "    #Define figure subplots\n",
    "    fig = plt.figure(1)\n",
    "    fig.subplots_adjust(bottom= -1, left=0.025, top = 2, right=0.975)\n",
    "    \n",
    "    #Loop through features    \n",
    "    i = 1\n",
    "    for col in features.columns:\n",
    "        \n",
    "        #Set subplot and plot format        \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set_context(\"paper\", font_scale = 0.5, rc={\"lines.linewidth\": 1})\n",
    "        plt.subplot(7,7,0 + i)\n",
    "        j = i - 1\n",
    "        \n",
    "        #Plot KDE for all labels\n",
    "        sns.distplot(inputs[inputs['label'] == 'Win'].iloc[:,j], hist = False, label = 'Win')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Draw'].iloc[:,j], hist = False, label = 'Draw')\n",
    "        sns.distplot(inputs[inputs['label'] == 'Defeat'].iloc[:,j], hist = False, label = 'Defeat')\n",
    "        plt.legend();\n",
    "        i = i + 1\n",
    "    \n",
    "    #Define plot format    \n",
    "    #DefaultSize = fig.get_size_inches()\n",
    "    fig.set_size_inches((DefaultSize[0]*1.2, DefaultSize[1]*1.2))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #Compute and print label weights\n",
    "    labels = inputs.loc[:,'label']\n",
    "    class_weights = labels.value_counts() / len(labels)\n",
    "    print(class_weights)\n",
    "    \n",
    "    #Store description of all features\n",
    "    feature_details = features.describe().transpose()\n",
    "\n",
    "    #Return feature details\n",
    "    return feature_details\n",
    "    \n",
    "def find_best_classifier(classifiers, dm_reductions, scorer, X_t, y_t, X_c, y_c, X_v, y_v, cv_sets, params, jobs):\n",
    "    ''' Tune all classifier and dimensionality reduction combiantions to find best classifier. '''\n",
    "    \n",
    "    #Initialize result storage\n",
    "    clfs_return = []\n",
    "    dm_reduce_return = []\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    #Loop through dimensionality reductions\n",
    "    for dm in dm_reductions:\n",
    "        \n",
    "        #Loop through classifiers\n",
    "        for clf in clfs:\n",
    "            \n",
    "            #Grid search, calibrate, and test the classifier\n",
    "            clf, dm_reduce, train_score, test_score = train_calibrate_predict(clf = clf, dm_reduction = dm, X_train = X_t, y_train = y_t,\n",
    "                                                      X_calibrate = X_c, y_calibrate = y_c,\n",
    "                                                      X_test = X_v, y_test = y_v, cv_sets = cv_sets,\n",
    "                                                      params = params[clf], scorer = scorer, jobs = jobs, use_grid_search = True)\n",
    "            \n",
    "            #Append the result to storage            \n",
    "            clfs_return.append(clf)\n",
    "            dm_reduce_return.append(dm_reduce)\n",
    "            train_scores.append(train_score)\n",
    "            test_scores.append(test_score)\n",
    "    \n",
    "    #Return storage\n",
    "    return clfs_return, dm_reduce_return, train_scores, test_scores\n",
    "\n",
    "def plot_training_results(clfs, dm_reductions, train_scores, test_scores, path):\n",
    "    ''' Plot results of classifier training. '''\n",
    "    \n",
    "    #Set graph format\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale = 1, rc={\"lines.linewidth\": 1})\n",
    "    ax = plt.subplot(111)\n",
    "    w = 0.5\n",
    "    x = np.arange(len(train_scores))\n",
    "    ax.set_yticks(x + w)\n",
    "    ax.legend((train_scores[0], test_scores[0]), (\"Train Scores\", \"Test Scores\"))\n",
    "    names = []\n",
    "    \n",
    "    #Loop throuugh classifiers\n",
    "    for i in range(0, len(clfs)): \n",
    "        \n",
    "        #Define temporary variables        \n",
    "        clf = clfs[i]\n",
    "        clf_name = clf.base_estimator.__class__.__name__\n",
    "        dm = dm_reductions[i]\n",
    "        dm_name = dm.__class__.__name__\n",
    "        \n",
    "        #Create and store name\n",
    "        name = \"{} with {}\".format(clf_name, dm_name)\n",
    "        names.append(name)\n",
    "        \n",
    "    #Plot all names in horizontal bar plot\n",
    "    ax.set_yticklabels((names))\n",
    "    plt.xlim(0.5, 0.55)\n",
    "    plt.barh(x, test_scores, color = 'b', alpha = 0.6)\n",
    "    plt.title(\"Test Data Accuracy Scores\")\n",
    "    fig = plt.figure(1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def optimize_betting(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, match_data, fifa_data,\n",
    "                     n_samples, sample_size, parameter_1_grid, parameter_2_grid, verbose = False):\n",
    "    ''' Tune parameters of bet selection algorithm. '''\n",
    "    \n",
    "    #Generate data samples\n",
    "    samples = []\n",
    "    for i in range(0, n_samples):\n",
    "        sample = match_data.sample(n = sample_size, random_state = 42)\n",
    "        samples.append(sample)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [\"parameter_1\", \"parameter_2\", \"results\"])\n",
    "    row = 0\n",
    "    \n",
    "    #Iterate over all 1 parameter\n",
    "    for i in parameter_1_grid:\n",
    "        \n",
    "        #Iterate over all 2 parameter\n",
    "        for j in parameter_2_grid:\n",
    "            \n",
    "            #Compute average score over all samples\n",
    "            profits = []\n",
    "            for sample in samples:\n",
    "                choices = find_good_bets(best_clf, best_dm_reduce, bk_cols_selected, bk_cols, sample, fifa_data, i, j)\n",
    "                profit = execute_bets(choices, match_data)\n",
    "                profits.append(profit)\n",
    "            result = np.mean(np.array(profits))\n",
    "            results.loc[row,\"results\"] = result\n",
    "            results.loc[row,\"parameter_1\"] = i\n",
    "            results.loc[row,\"parameter_2\"] = j\n",
    "            row = row + 1\n",
    "            if verbose == True: print(\"Simulated parameter combination: {}\".format(row))\n",
    "               \n",
    "    #Return best setting and result\n",
    "    best_result = results.ix[results['results'].idxmax()] \n",
    "    return best_result\n",
    "    \n",
    "    \n",
    "def plot_bookkeeper_cf_matrix(matches, bookkeepers, path, verbose = False, normalize = True):\n",
    "    ''' Plot confusion matrix of bookkeeper predictions. '''\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining labels...\")\n",
    "    \n",
    "    #Get match labels\n",
    "    y_test_temp = matches.apply(get_match_label, axis = 1)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper probabilities...\")\n",
    "    \n",
    "    #Get bookkeeper probabilities\n",
    "    bookkeeper_probs = get_bookkeeper_probs(matches, bookkeepers)\n",
    "    bookkeeper_probs.reset_index(inplace = True, drop = True)\n",
    "    bookkeeper_probs.dropna(inplace = True)\n",
    "    \n",
    "    if verbose == True: print(\"Obtaining bookkeeper labels...\")\n",
    "    \n",
    "    #Get bookkeeper labels\n",
    "    y_pred_temp = pd.DataFrame()\n",
    "    y_pred_temp.loc[:,'bk_label'] = bookkeeper_probs[['Win', 'Draw', 'Defeat']].idxmax(axis = 1)\n",
    "    y_pred_temp.loc[:,'match_api_id'] = bookkeeper_probs.loc[:, 'match_api_id']\n",
    "    \n",
    "    if verbose == True: print(\"Plotting confusion matrix...\")\n",
    "    \n",
    "    #Format data\n",
    "    results = pd.merge(y_pred_temp, y_test_temp, on = 'match_api_id', how = 'left')\n",
    "    y_test = results.loc[:, 'label']\n",
    "    y_pred = results.loc[:, 'bk_label']\n",
    "    \n",
    "    #Generate confusion matrix\n",
    "    labels = [\"Win\", \"Draw\", \"Defeat\"]\n",
    "    cm = confusion_matrix(y_test, y_pred, labels) \n",
    "    \n",
    "    #Check for normalization\n",
    "    if normalize == True:\n",
    "        cm = cm.astype('float') / cm.sum()\n",
    "        \n",
    "    #Plot confusion matrix\n",
    "    sns.set_style(\"whitegrid\", {\"axes.grid\" : False})\n",
    "    fig = plt.figure(1)    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap = plt.cm.Blues)\n",
    "    title = \"Confusion matrix of Bookkeeper predictions!\"   \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j], 2),\n",
    "                 horizontalalignmenSt=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #Print classification report and accuracy score of bookkeepers\n",
    "    print(classification_report(y_test, y_pred)) \n",
    "    print(\"Bookkeeper score for test set: {:.4f}.\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-477a508b8abb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplayer_stats_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM Player_Attributes;\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mteam_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM Team;\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM Match;\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Reduce match data to fulfill run time requirements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joão abelha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m         return pandas_sql.read_query(\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joão abelha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m   1644\u001b[0m             )\n\u001b[0;32m   1645\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetchall_as_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1647\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joão abelha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m_fetchall_as_list\u001b[1;34m(self, cur)\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fetchall_as_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Fetching data\n",
    "#Connecting to database\n",
    "path = \"\"\n",
    "database = path + 'database.sqlite'\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_colwidth',1000)\n",
    "\n",
    "# Fetching required data tables\n",
    "player_data = pd.read_sql(\"SELECT * FROM Player;\", conn)\n",
    "player_stats_data = pd.read_sql(\"SELECT * FROM Player_Attributes;\", conn)\n",
    "team_data = pd.read_sql(\"SELECT * FROM Team;\", conn)\n",
    "match_data = pd.read_sql(\"SELECT * FROM Match;\", conn)\n",
    "\n",
    "# Reduce match data to fulfill run time requirements\n",
    "rows = [\"country_id\", \"league_id\", \"season\", \"stage\", \"date\", \"match_api_id\", \"home_team_api_id\", \n",
    "        \"away_team_api_id\", \"home_team_goal\", \"away_team_goal\", \"home_player_1\", \"home_player_2\",\n",
    "        \"home_player_3\", \"home_player_4\", \"home_player_5\", \"home_player_6\", \"home_player_7\", \n",
    "        \"home_player_8\", \"home_player_9\", \"home_player_10\", \"home_player_11\", \"away_player_1\",\n",
    "        \"away_player_2\", \"away_player_3\", \"away_player_4\", \"away_player_5\", \"away_player_6\",\n",
    "        \"away_player_7\", \"away_player_8\", \"away_player_9\", \"away_player_10\", \"away_player_11\"]\n",
    "\n",
    "# Drops rows with NaN values\n",
    "match_data.dropna(subset = rows, inplace = True)\n",
    "\n",
    "# We're only using 1500 matches right now!!!\n",
    "# match_data = match_data.head(1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating features, exploring the data, and preparing data for model training\n",
    "\n",
    "# Gets players fifa overall ratings for each match\n",
    "fifa_data = get_fifa_data(match_data, player_stats_data, data_exists = False)\n",
    "\n",
    "odds = ['B365', 'BW', 'IW', 'LB', 'PS', 'WH', 'SJ', 'VC', 'GB', 'BS']\n",
    "feables = create_feables(match_data, fifa_data, odds, get_overall = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "feables.to_csv(\"feables.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21374, 23)\n"
     ]
    }
   ],
   "source": [
    "input = feables\n",
    "input['odds_home'] = (input['B365_Win'] + input['BW_Win'] + input['IW_Win'] + input['LB_Win'] + input['PS_Win'] + input['WH_Win'] + input['SJ_Win'] + input['VC_Win'] + input['GB_Win'] + input['BS_Win']) / 10.0\n",
    "input['odds_draw'] = (input['B365_Draw'] + input['BW_Draw'] + input['IW_Draw'] + input['LB_Draw'] + input['PS_Draw'] + input['WH_Draw'] + input['SJ_Draw'] + input['VC_Draw'] + input['GB_Draw'] + input['BS_Draw']) / 10.0\n",
    "input['odds_away'] = (input['B365_Defeat'] + input['BW_Defeat'] + input['IW_Defeat'] + input['LB_Defeat'] + input['PS_Defeat'] + input['WH_Defeat'] + input['SJ_Defeat'] + input['VC_Defeat'] + input['GB_Defeat'] + input['BS_Defeat']) / 10.0\n",
    "\n",
    "# Reduce match data to fulfill run time requirements\n",
    "rows = [\"home_team_goals_difference\", \"away_team_goals_difference\", \"games_won_home_team\",\t\"games_won_away_team\",\t\"games_against_home\",\t\"games_against_away\",\"home_player_1_overall_rating\", \"home_player_2_overall_rating\",\n",
    "        \"home_player_3_overall_rating\", \"home_player_4_overall_rating\", \"home_player_5_overall_rating\", \"home_player_6_overall_rating\", \"home_player_7_overall_rating\", \n",
    "        \"home_player_8_overall_rating\", \"home_player_9_overall_rating\", \"home_player_10_overall_rating\", \"home_player_11_overall_rating\", \"away_player_1_overall_rating\",\n",
    "        \"away_player_2_overall_rating\", \"away_player_3_overall_rating\", \"away_player_4_overall_rating\", \"away_player_5_overall_rating\", \"away_player_6_overall_rating\",\n",
    "        \"away_player_7_overall_rating\", \"away_player_8_overall_rating\", \"away_player_9_overall_rating\", \"away_player_10_overall_rating\", \"away_player_11_overall_rating\", \"odds_home\", \"odds_draw\", \"odds_away\", \"label\"]\n",
    "\n",
    "input = input[rows]\n",
    "\n",
    "labels = input.loc[:,'label']\n",
    "print(fifa_data.shape)\n",
    "\n",
    "features = input.drop('label', axis = 1)\n",
    "labels.to_csv(\"labels.csv\", sep=',')\n",
    "features.to_csv(\"features.csv\", sep=',')\n",
    "\n",
    "# Features Columns\n",
    "\n",
    "# home_team_goals_difference - goals difference in the last 10 games\n",
    "#away_team_goals_difference - goals difference in the last 10 games\n",
    "#games_won_home_team - victories in the last 10 games\n",
    "#games_won_away_team - victories in the last 10 games\n",
    "#games_against_home - won games by the home team, between the two teams\n",
    "#games_against_away - won games by the visitor team, between the two teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Features      Score\n",
      "28                      odds_home  14.812595\n",
      "30                      odds_away  13.510082\n",
      "29                      odds_draw   9.411810\n",
      "3             games_won_away_team   9.164181\n",
      "1      away_team_goals_difference   9.001905\n",
      "19   away_player_3_overall_rating   6.916504\n",
      "7    home_player_2_overall_rating   6.635907\n",
      "18   away_player_2_overall_rating   6.362262\n",
      "14   home_player_9_overall_rating   5.053426\n",
      "10   home_player_5_overall_rating   5.029158\n",
      "12   home_player_7_overall_rating   4.029868\n",
      "27  away_player_11_overall_rating   4.027402\n",
      "26  away_player_10_overall_rating   3.875786\n",
      "0      home_team_goals_difference   3.662570\n",
      "15  home_player_10_overall_rating   3.634490\n",
      "4              games_against_home   3.499859\n",
      "23   away_player_7_overall_rating   3.386378\n",
      "6    home_player_1_overall_rating   3.114271\n",
      "16  home_player_11_overall_rating   2.940083\n",
      "22   away_player_6_overall_rating   2.717531\n",
      "20   away_player_4_overall_rating   2.584002\n",
      "24   away_player_8_overall_rating   2.564272\n",
      "2             games_won_home_team   2.493711\n",
      "5              games_against_away   2.428216\n",
      "13   home_player_8_overall_rating   2.030992\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "##### FEATURE SELECTION #####\n",
    "#############################\n",
    "\n",
    "# Univariate Selection - uses statistical tests that can be used to select those features that have the strongest relationship with the output variable.\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=25)\n",
    "fit = bestfeatures.fit(features, labels)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(features.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Features','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(25,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0249531  0.03312031 0.02880762 0.03759982 0.02199327 0.0291054\n",
      " 0.0332723  0.03357567 0.02683673 0.02793434 0.05011864 0.02609968\n",
      " 0.0299703  0.03232617 0.02570358 0.03038333 0.02746241 0.03499141\n",
      " 0.04566834 0.03395811 0.03983141 0.03914122 0.03594201 0.0290082\n",
      " 0.02787861 0.03594584 0.02064527 0.0260219  0.02860576 0.03785417\n",
      " 0.04524506]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################\n",
    "##### FEATURE SELECTION #####\n",
    "#############################\n",
    "\n",
    "# Feature Importance - uses statistical tests that can be used to select those features that have the strongest relationship with the output variable.       \n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(features, labels)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=features.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>variances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home_team_goals_difference</td>\n",
       "      <td>2.725952e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>away_team_goals_difference</td>\n",
       "      <td>2.564478e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>games_won_home_team</td>\n",
       "      <td>6.217369e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>games_won_away_team</td>\n",
       "      <td>5.158144e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>games_against_home</td>\n",
       "      <td>3.112892e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>games_against_away</td>\n",
       "      <td>2.944180e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>home_player_1_overall_rating</td>\n",
       "      <td>2.630048e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>home_player_2_overall_rating</td>\n",
       "      <td>2.500191e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home_player_3_overall_rating</td>\n",
       "      <td>2.449763e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>home_player_4_overall_rating</td>\n",
       "      <td>2.228747e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>home_player_5_overall_rating</td>\n",
       "      <td>1.952686e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home_player_6_overall_rating</td>\n",
       "      <td>1.837246e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_player_7_overall_rating</td>\n",
       "      <td>1.676188e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>home_player_8_overall_rating</td>\n",
       "      <td>1.652000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>home_player_9_overall_rating</td>\n",
       "      <td>1.564932e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>home_player_10_overall_rating</td>\n",
       "      <td>1.536035e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>home_player_11_overall_rating</td>\n",
       "      <td>1.402482e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>away_player_1_overall_rating</td>\n",
       "      <td>1.351884e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>away_player_2_overall_rating</td>\n",
       "      <td>1.297806e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>away_player_3_overall_rating</td>\n",
       "      <td>1.201229e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>away_player_4_overall_rating</td>\n",
       "      <td>1.102866e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>away_player_5_overall_rating</td>\n",
       "      <td>1.024792e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>away_player_6_overall_rating</td>\n",
       "      <td>9.256787e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>away_player_7_overall_rating</td>\n",
       "      <td>7.379030e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>away_player_8_overall_rating</td>\n",
       "      <td>2.006986e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>away_player_9_overall_rating</td>\n",
       "      <td>1.709585e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>away_player_10_overall_rating</td>\n",
       "      <td>1.524401e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>away_player_11_overall_rating</td>\n",
       "      <td>6.582069e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>odds_home</td>\n",
       "      <td>6.345128e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>odds_draw</td>\n",
       "      <td>8.578568e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>odds_away</td>\n",
       "      <td>1.796257e-33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features     variances\n",
       "0      home_team_goals_difference  2.725952e-01\n",
       "1      away_team_goals_difference  2.564478e-01\n",
       "2             games_won_home_team  6.217369e-02\n",
       "3             games_won_away_team  5.158144e-02\n",
       "4              games_against_home  3.112892e-02\n",
       "5              games_against_away  2.944180e-02\n",
       "6    home_player_1_overall_rating  2.630048e-02\n",
       "7    home_player_2_overall_rating  2.500191e-02\n",
       "8    home_player_3_overall_rating  2.449763e-02\n",
       "9    home_player_4_overall_rating  2.228747e-02\n",
       "10   home_player_5_overall_rating  1.952686e-02\n",
       "11   home_player_6_overall_rating  1.837246e-02\n",
       "12   home_player_7_overall_rating  1.676188e-02\n",
       "13   home_player_8_overall_rating  1.652000e-02\n",
       "14   home_player_9_overall_rating  1.564932e-02\n",
       "15  home_player_10_overall_rating  1.536035e-02\n",
       "16  home_player_11_overall_rating  1.402482e-02\n",
       "17   away_player_1_overall_rating  1.351884e-02\n",
       "18   away_player_2_overall_rating  1.297806e-02\n",
       "19   away_player_3_overall_rating  1.201229e-02\n",
       "20   away_player_4_overall_rating  1.102866e-02\n",
       "21   away_player_5_overall_rating  1.024792e-02\n",
       "22   away_player_6_overall_rating  9.256787e-03\n",
       "23   away_player_7_overall_rating  7.379030e-03\n",
       "24   away_player_8_overall_rating  2.006986e-03\n",
       "25   away_player_9_overall_rating  1.709585e-03\n",
       "26  away_player_10_overall_rating  1.524401e-03\n",
       "27  away_player_11_overall_rating  6.582069e-04\n",
       "28                      odds_home  6.345128e-06\n",
       "29                      odds_draw  8.578568e-07\n",
       "30                      odds_away  1.796257e-33"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################\n",
    "##### FEATURE SELECTION #####\n",
    "#############################\n",
    "\n",
    "# Principal Component Analysis (PCA) - using the data covariance and it's eigenvalue decomposition, calculates the most relevant features on the dataset\n",
    "pca = PCA(n_components=31)\n",
    "pca.fit(features)\n",
    "variances = pd.DataFrame()\n",
    "variances.loc[:,'features'] = features.columns\n",
    "variances.loc[:,'variances'] = pca.explained_variance_ratio_ \n",
    "\n",
    "variances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Results (poderão mudar se alterarmos as variáveis iniciais)\n",
    "\n",
    "By analyzing the results of the 3 techniques applied (Univariate Selection, Feature Importance and PCA) we can conclude that there isn't any feature that has a special relevance on the output. Meaning that the output depends not of a specific feature, but of the features as a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Use of DecisionTreeClassifier with and without k-fold cross-validation,  GridSearchCV for parameter tunning \n",
    "and use of Random Forest Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c90482730658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mall_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "all_inputs = input.loc[:, input.columns != 'label'].values\n",
    "all_labels = input.label.values\n",
    "\n",
    "#all_inputs[:5]\n",
    "\n",
    "(training_inputs,\n",
    " testing_inputs,\n",
    " training_classes,\n",
    " testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decion tree classifier (not very good classifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "decision_tree_classifier.fit(training_inputs, training_classes)\n",
    "\n",
    "# Validate the classifier on the testing set using classification accuracy\n",
    "decision_tree_classifier.score(testing_inputs, testing_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from this we can see that the problem is dependent on the subset we are\n",
    "# using => overfitting\n",
    "model_accuracies = []\n",
    "\n",
    "for repetition in range(1000):\n",
    "    (training_inputs,\n",
    "     testing_inputs,\n",
    "     training_classes,\n",
    "     testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25)\n",
    "    \n",
    "    decision_tree_classifier = DecisionTreeClassifier()\n",
    "    decision_tree_classifier.fit(training_inputs, training_classes)\n",
    "    classifier_accuracy = decision_tree_classifier.score(testing_inputs, testing_classes)\n",
    "    model_accuracies.append(classifier_accuracy)\n",
    "    \n",
    "plt.hist(model_accuracies)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation\n",
    "def plot_cv(cv, features, labels):\n",
    "    masks = []\n",
    "    for train, test in cv.split(features, labels):\n",
    "        mask = np.zeros(len(labels), dtype=bool)\n",
    "        mask[test] = 1\n",
    "        masks.append(mask)\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(masks, interpolation='none', cmap='gray_r')\n",
    "    plt.ylabel('Fold')\n",
    "    plt.xlabel('Row #')\n",
    "\n",
    "plot_cv(StratifiedKFold(n_splits=10), all_inputs, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a more consistent rating: however is not that good\n",
    "from sklearn.model_selection import cross_val_score\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# cross_val_score returns a list of the scores, which we can visualize\n",
    "# to get a reasonable estimate of our classifier's performance\n",
    "cv_scores = cross_val_score(decision_tree_classifier, all_inputs, all_labels, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "cv_scores = cross_val_score(decision_tree_classifier, all_inputs, all_labels, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "parameter_grid = {'max_depth': [1, 2, 3, 4, 5],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree_classifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_visualization = grid_search.cv_results_['mean_test_score']\n",
    "grid_visualization.shape = (5, 4)\n",
    "sns.heatmap(grid_visualization, cmap='Blues', annot=True)\n",
    "plt.xticks(np.arange(4) + 0.5, grid_search.param_grid['max_features'])\n",
    "plt.yticks(np.arange(5) + 0.5, grid_search.param_grid['max_depth'])\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('max_depth')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "                  'splitter': ['best', 'random'],\n",
    "                  'max_depth': [1, 2, 3, 4, 5],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree_classifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = grid_search.best_estimator_\n",
    "decision_tree_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "\n",
    "parameter_grid = {'n_estimators': [10, 25, 50, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(random_forest_classifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_forest_classifier = grid_search.best_estimator_\n",
    "\n",
    "rf_df = pd.DataFrame({'accuracy': cross_val_score(random_forest_classifier, all_inputs, all_labels, cv=10),\n",
    "                       'classifier': ['Random Forest'] * 10})\n",
    "dt_df = pd.DataFrame({'accuracy': cross_val_score(decision_tree_classifier, all_inputs, all_labels, cv=10),\n",
    "                      'classifier': ['Decision Tree'] * 10})\n",
    "both_df = rf_df.append(dt_df)\n",
    "\n",
    "sns.boxplot(x='classifier', y='accuracy', data=both_df)\n",
    "sns.stripplot(x='classifier', y='accuracy', data=both_df, jitter=True, color='black')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read processed data from file\n",
    "\n",
    "<p>Reading the labels and the features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      home_team_goals_difference  away_team_goals_difference  \\\n",
      "0                           -9.0                         7.0   \n",
      "1                           -5.0                       -12.0   \n",
      "2                            5.0                         3.0   \n",
      "3                            0.0                        -5.0   \n",
      "4                           11.0                         0.0   \n",
      "5                            6.0                        -7.0   \n",
      "6                           14.0                         7.0   \n",
      "7                            2.0                        10.0   \n",
      "8                           -2.0                         0.0   \n",
      "9                           -9.0                        -4.0   \n",
      "10                           3.0                       -14.0   \n",
      "11                          -1.0                        -3.0   \n",
      "12                           1.0                         2.0   \n",
      "13                         -10.0                         0.0   \n",
      "14                           8.0                       -10.0   \n",
      "15                           5.0                         0.0   \n",
      "16                           2.0                         2.0   \n",
      "17                           6.0                        -2.0   \n",
      "18                           4.0                        13.0   \n",
      "19                          -2.0                       -13.0   \n",
      "20                          -1.0                         2.0   \n",
      "21                         -15.0                         0.0   \n",
      "22                           8.0                        -1.0   \n",
      "23                           1.0                       -15.0   \n",
      "24                          -1.0                        -2.0   \n",
      "25                          -1.0                        10.0   \n",
      "26                         -10.0                        10.0   \n",
      "27                           3.0                         8.0   \n",
      "28                          -1.0                        -1.0   \n",
      "29                         -12.0                         2.0   \n",
      "...                          ...                         ...   \n",
      "2597                         3.0                       -14.0   \n",
      "2598                        11.0                         5.0   \n",
      "2599                        -3.0                         2.0   \n",
      "2600                       -14.0                        -4.0   \n",
      "2601                        -3.0                         3.0   \n",
      "2602                         3.0                        -7.0   \n",
      "2603                         4.0                        -8.0   \n",
      "2604                        -1.0                         2.0   \n",
      "2605                        26.0                        17.0   \n",
      "2606                       -16.0                        -5.0   \n",
      "2607                       -12.0                        -8.0   \n",
      "2608                         4.0                         1.0   \n",
      "2609                        -3.0                        12.0   \n",
      "2610                        -5.0                        -1.0   \n",
      "2611                         3.0                       -11.0   \n",
      "2612                        -4.0                        -4.0   \n",
      "2613                        -5.0                         1.0   \n",
      "2614                         3.0                         1.0   \n",
      "2615                        14.0                         1.0   \n",
      "2616                        -6.0                        19.0   \n",
      "2617                        -8.0                         4.0   \n",
      "2618                         0.0                        -4.0   \n",
      "2619                        13.0                        -1.0   \n",
      "2620                        -2.0                         0.0   \n",
      "2621                        -9.0                        -5.0   \n",
      "2622                        -2.0                        -7.0   \n",
      "2623                         3.0                         5.0   \n",
      "2624                        -1.0                        13.0   \n",
      "2625                        -1.0                        -8.0   \n",
      "2626                        -8.0                        17.0   \n",
      "\n",
      "      games_won_home_team  games_won_away_team  games_against_home  \\\n",
      "0                     2.0                  6.0                 0.0   \n",
      "1                     2.0                  1.0                 0.0   \n",
      "2                     5.0                  4.0                 0.0   \n",
      "3                     4.0                  2.0                 0.0   \n",
      "4                     8.0                  0.0                 0.0   \n",
      "5                     5.0                  4.0                 2.0   \n",
      "6                     7.0                  5.0                 0.0   \n",
      "7                     4.0                  6.0                 0.0   \n",
      "8                     4.0                  4.0                 1.0   \n",
      "9                     2.0                  2.0                 0.0   \n",
      "10                    5.0                  1.0                 1.0   \n",
      "11                    4.0                  1.0                 1.0   \n",
      "12                    3.0                  5.0                 0.0   \n",
      "13                    0.0                  4.0                 0.0   \n",
      "14                    5.0                  0.0                 0.0   \n",
      "15                    4.0                  4.0                 2.0   \n",
      "16                    4.0                  5.0                 3.0   \n",
      "17                    6.0                  3.0                 0.0   \n",
      "18                    3.0                  6.0                 1.0   \n",
      "19                    1.0                  2.0                 1.0   \n",
      "20                    3.0                  4.0                 0.0   \n",
      "21                    1.0                  3.0                 2.0   \n",
      "22                    5.0                  3.0                 3.0   \n",
      "23                    4.0                  1.0                 1.0   \n",
      "24                    3.0                  3.0                 1.0   \n",
      "25                    4.0                  4.0                 1.0   \n",
      "26                    3.0                  6.0                 0.0   \n",
      "27                    6.0                  5.0                 1.0   \n",
      "28                    3.0                  1.0                 1.0   \n",
      "29                    0.0                  5.0                 0.0   \n",
      "...                   ...                  ...                 ...   \n",
      "2597                  5.0                  0.0                 0.0   \n",
      "2598                  7.0                  5.0                 1.0   \n",
      "2599                  4.0                  5.0                 0.0   \n",
      "2600                  1.0                  3.0                 2.0   \n",
      "2601                  4.0                  4.0                 0.0   \n",
      "2602                  6.0                  2.0                 2.0   \n",
      "2603                  6.0                  2.0                 0.0   \n",
      "2604                  2.0                  4.0                 0.0   \n",
      "2605                  9.0                  7.0                 1.0   \n",
      "2606                  3.0                  2.0                 0.0   \n",
      "2607                  0.0                  4.0                 2.0   \n",
      "2608                  5.0                  4.0                 2.0   \n",
      "2609                  4.0                  8.0                 0.0   \n",
      "2610                  3.0                  5.0                 1.0   \n",
      "2611                  4.0                  2.0                 2.0   \n",
      "2612                  3.0                  4.0                 1.0   \n",
      "2613                  3.0                  5.0                 1.0   \n",
      "2614                  4.0                  5.0                 1.0   \n",
      "2615                  6.0                  3.0                 0.0   \n",
      "2616                  2.0                  8.0                 0.0   \n",
      "2617                  1.0                  5.0                 0.0   \n",
      "2618                  4.0                  4.0                 0.0   \n",
      "2619                  9.0                  3.0                 2.0   \n",
      "2620                  4.0                  4.0                 1.0   \n",
      "2621                  2.0                  3.0                 0.0   \n",
      "2622                  5.0                  2.0                 1.0   \n",
      "2623                  6.0                  5.0                 0.0   \n",
      "2624                  4.0                  6.0                 0.0   \n",
      "2625                  3.0                  1.0                 0.0   \n",
      "2626                  4.0                  8.0                 0.0   \n",
      "\n",
      "      games_against_away  home_player_1_overall_rating  \\\n",
      "0                    1.0                          71.0   \n",
      "1                    1.0                          64.0   \n",
      "2                    2.0                          69.0   \n",
      "3                    0.0                          69.0   \n",
      "4                    0.0                          65.0   \n",
      "5                    1.0                          66.0   \n",
      "6                    3.0                          71.0   \n",
      "7                    3.0                          71.0   \n",
      "8                    1.0                          71.0   \n",
      "9                    0.0                          57.0   \n",
      "10                   1.0                          68.0   \n",
      "11                   0.0                          72.0   \n",
      "12                   2.0                          65.0   \n",
      "13                   0.0                          65.0   \n",
      "14                   0.0                          74.0   \n",
      "15                   1.0                          65.0   \n",
      "16                   0.0                          71.0   \n",
      "17                   1.0                          68.0   \n",
      "18                   1.0                          66.0   \n",
      "19                   0.0                          63.0   \n",
      "20                   1.0                          63.0   \n",
      "21                   1.0                          67.0   \n",
      "22                   0.0                          71.0   \n",
      "23                   1.0                          71.0   \n",
      "24                   0.0                          71.0   \n",
      "25                   1.0                          71.0   \n",
      "26                   0.0                          57.0   \n",
      "27                   1.0                          66.0   \n",
      "28                   0.0                          65.0   \n",
      "29                   0.0                          65.0   \n",
      "...                  ...                           ...   \n",
      "2597                 0.0                          72.0   \n",
      "2598                 1.0                          79.0   \n",
      "2599                 1.0                          57.0   \n",
      "2600                 1.0                          79.0   \n",
      "2601                 1.0                          75.0   \n",
      "2602                 0.0                          79.0   \n",
      "2603                 0.0                          77.0   \n",
      "2604                 0.0                          67.0   \n",
      "2605                 1.0                          85.0   \n",
      "2606                 0.0                          70.0   \n",
      "2607                 0.0                          77.0   \n",
      "2608                 0.0                          76.0   \n",
      "2609                 2.0                          66.0   \n",
      "2610                 1.0                          77.0   \n",
      "2611                 0.0                          79.0   \n",
      "2612                 1.0                          75.0   \n",
      "2613                 1.0                          76.0   \n",
      "2614                 0.0                          74.0   \n",
      "2615                 0.0                          89.0   \n",
      "2616                 2.0                          78.0   \n",
      "2617                 3.0                          77.0   \n",
      "2618                 0.0                          68.0   \n",
      "2619                 0.0                          79.0   \n",
      "2620                 2.0                          57.0   \n",
      "2621                 0.0                          79.0   \n",
      "2622                 1.0                          75.0   \n",
      "2623                 3.0                          79.0   \n",
      "2624                 2.0                          77.0   \n",
      "2625                 0.0                          76.0   \n",
      "2626                 1.0                          70.0   \n",
      "\n",
      "      home_player_2_overall_rating  home_player_3_overall_rating  \\\n",
      "0                             59.0                          61.0   \n",
      "1                             61.0                          69.0   \n",
      "2                             70.0                          72.0   \n",
      "3                             68.0                          69.0   \n",
      "4                             71.0                          72.0   \n",
      "5                             71.0                          65.0   \n",
      "6                             71.0                          73.0   \n",
      "7                             69.0                          70.0   \n",
      "8                             62.0                          67.0   \n",
      "9                             63.0                          62.0   \n",
      "10                            70.0                          67.0   \n",
      "11                            70.0                          69.0   \n",
      "12                            67.0                          70.0   \n",
      "13                            63.0                          64.0   \n",
      "14                            73.0                          74.0   \n",
      "15                            66.0                          64.0   \n",
      "16                            71.0                          73.0   \n",
      "17                            70.0                          67.0   \n",
      "18                            65.0                          70.0   \n",
      "19                            65.0                          64.0   \n",
      "20                            68.0                          64.0   \n",
      "21                            65.0                          63.0   \n",
      "22                            70.0                          71.0   \n",
      "23                            70.0                          61.0   \n",
      "24                            68.0                          73.0   \n",
      "25                            63.0                          62.0   \n",
      "26                            63.0                          62.0   \n",
      "27                            66.0                          65.0   \n",
      "28                            70.0                          66.0   \n",
      "29                            57.0                          63.0   \n",
      "...                            ...                           ...   \n",
      "2597                          72.0                          75.0   \n",
      "2598                          78.0                          78.0   \n",
      "2599                          72.0                          75.0   \n",
      "2600                          78.0                          74.0   \n",
      "2601                          72.0                          76.0   \n",
      "2602                          76.0                          74.0   \n",
      "2603                          72.0                          76.0   \n",
      "2604                          74.0                          72.0   \n",
      "2605                          84.0                          86.0   \n",
      "2606                          72.0                          68.0   \n",
      "2607                          73.0                          76.0   \n",
      "2608                          77.0                          79.0   \n",
      "2609                          71.0                          74.0   \n",
      "2610                          71.0                          73.0   \n",
      "2611                          73.0                          84.0   \n",
      "2612                          75.0                          76.0   \n",
      "2613                          73.0                          73.0   \n",
      "2614                          74.0                          77.0   \n",
      "2615                          87.0                          76.0   \n",
      "2616                          72.0                          75.0   \n",
      "2617                          71.0                          73.0   \n",
      "2618                          72.0                          71.0   \n",
      "2619                          78.0                          78.0   \n",
      "2620                          72.0                          75.0   \n",
      "2621                          78.0                          74.0   \n",
      "2622                          72.0                          68.0   \n",
      "2623                          76.0                          71.0   \n",
      "2624                          67.0                          76.0   \n",
      "2625                          74.0                          72.0   \n",
      "2626                          72.0                          71.0   \n",
      "\n",
      "      home_player_4_overall_rating  ...  away_player_5_overall_rating  \\\n",
      "0                             67.0  ...                          66.0   \n",
      "1                             64.0  ...                          63.0   \n",
      "2                             66.0  ...                          64.0   \n",
      "3                             64.0  ...                          60.0   \n",
      "4                             73.0  ...                          60.0   \n",
      "5                             64.0  ...                          65.0   \n",
      "6                             70.0  ...                          69.0   \n",
      "7                             72.0  ...                          70.0   \n",
      "8                             62.0  ...                          73.0   \n",
      "9                             63.0  ...                          66.0   \n",
      "10                            68.0  ...                          65.0   \n",
      "11                            70.0  ...                          58.0   \n",
      "12                            69.0  ...                          69.0   \n",
      "13                            63.0  ...                          66.0   \n",
      "14                            72.0  ...                          63.0   \n",
      "15                            67.0  ...                          64.0   \n",
      "16                            66.0  ...                          64.0   \n",
      "17                            57.0  ...                          69.0   \n",
      "18                            63.0  ...                          66.0   \n",
      "19                            65.0  ...                          62.0   \n",
      "20                            66.0  ...                          67.0   \n",
      "21                            64.0  ...                          66.0   \n",
      "22                            73.0  ...                          69.0   \n",
      "23                            71.0  ...                          69.0   \n",
      "24                            66.0  ...                          64.0   \n",
      "25                            67.0  ...                          62.0   \n",
      "26                            60.0  ...                          71.0   \n",
      "27                            69.0  ...                          68.0   \n",
      "28                            67.0  ...                          64.0   \n",
      "29                            64.0  ...                          58.0   \n",
      "...                            ...  ...                           ...   \n",
      "2597                          73.0  ...                          60.0   \n",
      "2598                          79.0  ...                          79.0   \n",
      "2599                          73.0  ...                          72.0   \n",
      "2600                          75.0  ...                          74.0   \n",
      "2601                          75.0  ...                          76.0   \n",
      "2602                          68.0  ...                          73.0   \n",
      "2603                          69.0  ...                          75.0   \n",
      "2604                          69.0  ...                          76.0   \n",
      "2605                          75.0  ...                          83.0   \n",
      "2606                          71.0  ...                          72.0   \n",
      "2607                          78.0  ...                          74.0   \n",
      "2608                          75.0  ...                          72.0   \n",
      "2609                          75.0  ...                          79.0   \n",
      "2610                          75.0  ...                          62.0   \n",
      "2611                          78.0  ...                          72.0   \n",
      "2612                          74.0  ...                          73.0   \n",
      "2613                          72.0  ...                          69.0   \n",
      "2614                          76.0  ...                          69.0   \n",
      "2615                          85.0  ...                          72.0   \n",
      "2616                          72.0  ...                          81.0   \n",
      "2617                          78.0  ...                          75.0   \n",
      "2618                          73.0  ...                          72.0   \n",
      "2619                          79.0  ...                          69.0   \n",
      "2620                          73.0  ...                          76.0   \n",
      "2621                          81.0  ...                          73.0   \n",
      "2622                          75.0  ...                          75.0   \n",
      "2623                          74.0  ...                          76.0   \n",
      "2624                          69.0  ...                          82.0   \n",
      "2625                          69.0  ...                          68.0   \n",
      "2626                          72.0  ...                          81.0   \n",
      "\n",
      "      away_player_6_overall_rating  away_player_7_overall_rating  \\\n",
      "0                             69.0                          68.0   \n",
      "1                             66.0                          67.0   \n",
      "2                             62.0                          61.0   \n",
      "3                             63.0                          64.0   \n",
      "4                             61.0                          67.0   \n",
      "5                             71.0                          64.0   \n",
      "6                             72.0                          72.0   \n",
      "7                             69.0                          71.0   \n",
      "8                             68.0                          64.0   \n",
      "9                             68.0                          65.0   \n",
      "10                            57.0                          69.0   \n",
      "11                            61.0                          65.0   \n",
      "12                            65.0                          67.0   \n",
      "13                            64.0                          68.0   \n",
      "14                            66.0                          67.0   \n",
      "15                            63.0                          66.0   \n",
      "16                            66.0                          65.0   \n",
      "17                            67.0                          68.0   \n",
      "18                            74.0                          70.0   \n",
      "19                            63.0                          64.0   \n",
      "20                            69.0                          62.0   \n",
      "21                            64.0                          66.0   \n",
      "22                            70.0                          67.0   \n",
      "23                            64.0                          64.0   \n",
      "24                            69.0                          61.0   \n",
      "25                            68.0                          65.0   \n",
      "26                            71.0                          67.0   \n",
      "27                            68.0                          72.0   \n",
      "28                            63.0                          63.0   \n",
      "29                            73.0                          59.0   \n",
      "...                            ...                           ...   \n",
      "2597                          68.0                          77.0   \n",
      "2598                          75.0                          72.0   \n",
      "2599                          68.0                          73.0   \n",
      "2600                          74.0                          69.0   \n",
      "2601                          79.0                          82.0   \n",
      "2602                          75.0                          76.0   \n",
      "2603                          77.0                          74.0   \n",
      "2604                          85.0                          72.0   \n",
      "2605                          83.0                          87.0   \n",
      "2606                          76.0                          70.0   \n",
      "2607                          75.0                          74.0   \n",
      "2608                          69.0                          73.0   \n",
      "2609                          77.0                          78.0   \n",
      "2610                          72.0                          71.0   \n",
      "2611                          75.0                          77.0   \n",
      "2612                          74.0                          74.0   \n",
      "2613                          74.0                          73.0   \n",
      "2614                          72.0                          75.0   \n",
      "2615                          73.0                          69.0   \n",
      "2616                          90.0                          85.0   \n",
      "2617                          75.0                          72.0   \n",
      "2618                          68.0                          73.0   \n",
      "2619                          73.0                          74.0   \n",
      "2620                          76.0                          79.0   \n",
      "2621                          75.0                          72.0   \n",
      "2622                          74.0                          69.0   \n",
      "2623                          76.0                          78.0   \n",
      "2624                          86.0                          87.0   \n",
      "2625                          73.0                          70.0   \n",
      "2626                          90.0                          83.0   \n",
      "\n",
      "      away_player_8_overall_rating  away_player_9_overall_rating  \\\n",
      "0                             68.0                          72.0   \n",
      "1                             62.0                          65.0   \n",
      "2                             66.0                          65.0   \n",
      "3                             59.0                          61.0   \n",
      "4                             66.0                          61.0   \n",
      "5                             66.0                          70.0   \n",
      "6                             71.0                          66.0   \n",
      "7                             76.0                          73.0   \n",
      "8                             65.0                          66.0   \n",
      "9                             63.0                          64.0   \n",
      "10                            70.0                          64.0   \n",
      "11                            65.0                          63.0   \n",
      "12                            65.0                          66.0   \n",
      "13                            66.0                          69.0   \n",
      "14                            63.0                          64.0   \n",
      "15                            68.0                          66.0   \n",
      "16                            67.0                          63.0   \n",
      "17                            70.0                          68.0   \n",
      "18                            72.0                          68.0   \n",
      "19                            61.0                          63.0   \n",
      "20                            71.0                          70.0   \n",
      "21                            66.0                          71.0   \n",
      "22                            68.0                          67.0   \n",
      "23                            69.0                          70.0   \n",
      "24                            64.0                          68.0   \n",
      "25                            63.0                          62.0   \n",
      "26                            76.0                          70.0   \n",
      "27                            71.0                          72.0   \n",
      "28                            65.0                          65.0   \n",
      "29                            67.0                          61.0   \n",
      "...                            ...                           ...   \n",
      "2597                          71.0                          71.0   \n",
      "2598                          80.0                          79.0   \n",
      "2599                          77.0                          74.0   \n",
      "2600                          74.0                          74.0   \n",
      "2601                          82.0                          81.0   \n",
      "2602                          75.0                          75.0   \n",
      "2603                          71.0                          72.0   \n",
      "2604                          76.0                          71.0   \n",
      "2605                          86.0                          87.0   \n",
      "2606                          75.0                          76.0   \n",
      "2607                          71.0                          66.0   \n",
      "2608                          74.0                          75.0   \n",
      "2609                          79.0                          73.0   \n",
      "2610                          76.0                          72.0   \n",
      "2611                          78.0                          76.0   \n",
      "2612                          72.0                          77.0   \n",
      "2613                          70.0                          64.0   \n",
      "2614                          73.0                          74.0   \n",
      "2615                          72.0                          74.0   \n",
      "2616                          87.0                          76.0   \n",
      "2617                          73.0                          79.0   \n",
      "2618                          77.0                          77.0   \n",
      "2619                          69.0                          75.0   \n",
      "2620                          76.0                          82.0   \n",
      "2621                          76.0                          75.0   \n",
      "2622                          71.0                          72.0   \n",
      "2623                          85.0                          77.0   \n",
      "2624                          86.0                          87.0   \n",
      "2625                          75.0                          76.0   \n",
      "2626                          87.0                          84.0   \n",
      "\n",
      "      away_player_10_overall_rating  away_player_11_overall_rating  odds_home  \\\n",
      "0                              66.0                           63.0   0.379532   \n",
      "1                              62.0                           66.0   0.503166   \n",
      "2                              72.0                           70.0   0.530293   \n",
      "3                              64.0                           56.0   0.580711   \n",
      "4                              66.0                           63.0   0.695433   \n",
      "5                              69.0                           63.0   0.528996   \n",
      "6                              74.0                           72.0   0.513034   \n",
      "7                              71.0                           77.0   0.317485   \n",
      "8                              69.0                           70.0   0.306530   \n",
      "9                              67.0                           68.0   0.421907   \n",
      "10                             65.0                           69.0   0.500483   \n",
      "11                             65.0                           66.0   0.530533   \n",
      "12                             68.0                           66.0   0.436676   \n",
      "13                             69.0                           66.0   0.360443   \n",
      "14                             66.0                           63.0   0.708239   \n",
      "15                             68.0                           72.0   0.589772   \n",
      "16                             68.0                           66.0   0.574525   \n",
      "17                             67.0                           70.0   0.461741   \n",
      "18                             70.0                           72.0   0.230077   \n",
      "19                             64.0                           64.0   0.479478   \n",
      "20                             61.0                           67.0   0.327765   \n",
      "21                             68.0                           68.0   0.397069   \n",
      "22                             70.0                           68.0   0.579354   \n",
      "23                             72.0                           65.0   0.612398   \n",
      "24                             66.0                           69.0   0.573247   \n",
      "25                             68.0                           67.0   0.488724   \n",
      "26                             71.0                           74.0   0.150452   \n",
      "27                             74.0                           66.0   0.376904   \n",
      "28                             65.0                           65.0   0.501535   \n",
      "29                             67.0                           66.0   0.310981   \n",
      "...                             ...                            ...        ...   \n",
      "2597                           80.0                           70.0   0.475474   \n",
      "2598                           75.0                           75.0   0.524064   \n",
      "2599                           77.0                           77.0   0.468138   \n",
      "2600                           73.0                           71.0   0.490216   \n",
      "2601                           76.0                           84.0   0.282579   \n",
      "2602                           74.0                           75.0   0.398077   \n",
      "2603                           74.0                           74.0   0.499737   \n",
      "2604                           75.0                           82.0   0.343421   \n",
      "2605                           92.0                           87.0   0.489329   \n",
      "2606                           76.0                           73.0   0.407656   \n",
      "2607                           71.0                           75.0   0.476514   \n",
      "2608                           70.0                           64.0   0.577973   \n",
      "2609                           79.0                           88.0   0.274264   \n",
      "2610                           72.0                           73.0   0.455701   \n",
      "2611                           80.0                           77.0   0.547142   \n",
      "2612                           73.0                           75.0   0.490474   \n",
      "2613                           72.0                           75.0   0.470648   \n",
      "2614                           72.0                           74.0   0.558276   \n",
      "2615                           74.0                           73.0   0.791144   \n",
      "2616                           94.0                           85.0   0.125358   \n",
      "2617                           74.0                           75.0   0.333361   \n",
      "2618                           79.0                           72.0   0.439596   \n",
      "2619                           72.0                           73.0   0.677984   \n",
      "2620                           66.0                           84.0   0.326380   \n",
      "2621                           74.0                           75.0   0.489335   \n",
      "2622                           74.0                           74.0   0.459102   \n",
      "2623                           78.0                           82.0   0.308310   \n",
      "2624                           92.0                           85.0   0.132418   \n",
      "2625                           76.0                           73.0   0.472065   \n",
      "2626                           94.0                           85.0   0.111772   \n",
      "\n",
      "      odds_draw  odds_away  \n",
      "0      0.287801   0.332667  \n",
      "1      0.266833   0.230001  \n",
      "2      0.264442   0.205265  \n",
      "3      0.246617   0.172672  \n",
      "4      0.190179   0.114387  \n",
      "5      0.257922   0.213083  \n",
      "6      0.264641   0.222325  \n",
      "7      0.284919   0.397596  \n",
      "8      0.275446   0.418024  \n",
      "9      0.282571   0.295523  \n",
      "10     0.268463   0.231054  \n",
      "11     0.263674   0.205793  \n",
      "12     0.286004   0.277320  \n",
      "13     0.285124   0.354433  \n",
      "14     0.180079   0.111682  \n",
      "15     0.235849   0.174378  \n",
      "16     0.246108   0.179367  \n",
      "17     0.276432   0.261826  \n",
      "18     0.258630   0.511293  \n",
      "19     0.277517   0.243005  \n",
      "20     0.286286   0.385949  \n",
      "21     0.289102   0.313829  \n",
      "22     0.238552   0.182094  \n",
      "23     0.230612   0.156990  \n",
      "24     0.242175   0.184578  \n",
      "25     0.264865   0.246411  \n",
      "26     0.228655   0.620893  \n",
      "27     0.285637   0.337458  \n",
      "28     0.270450   0.228015  \n",
      "29     0.282116   0.406903  \n",
      "...         ...        ...  \n",
      "2597   0.279635   0.244890  \n",
      "2598   0.261579   0.214357  \n",
      "2599   0.281810   0.250053  \n",
      "2600   0.276936   0.232848  \n",
      "2601   0.288622   0.428799  \n",
      "2602   0.294981   0.306942  \n",
      "2603   0.277235   0.223029  \n",
      "2604   0.290918   0.365661  \n",
      "2605   0.256098   0.254573  \n",
      "2606   0.289455   0.302890  \n",
      "2607   0.271339   0.252147  \n",
      "2608   0.249798   0.172229  \n",
      "2609   0.281432   0.444304  \n",
      "2610   0.282776   0.261524  \n",
      "2611   0.254605   0.198253  \n",
      "2612   0.276187   0.233339  \n",
      "2613   0.288582   0.240769  \n",
      "2614   0.255030   0.186694  \n",
      "2615   0.127395   0.081461  \n",
      "2616   0.194487   0.680155  \n",
      "2617   0.292443   0.374195  \n",
      "2618   0.288140   0.272263  \n",
      "2619   0.201577   0.120439  \n",
      "2620   0.288065   0.385555  \n",
      "2621   0.273647   0.237018  \n",
      "2622   0.287852   0.253046  \n",
      "2623   0.295389   0.396301  \n",
      "2624   0.213579   0.654002  \n",
      "2625   0.277108   0.250827  \n",
      "2626   0.178452   0.709775  \n",
      "\n",
      "[2627 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Upload data\n",
    "\n",
    "labels = pd.read_csv(\"labels.csv\", names=[\"match\", \"label\"])\n",
    "labels = labels.replace({'Defeat': 0}, regex=True)\n",
    "labels = labels.replace({'Draw': 1}, regex=True)\n",
    "labels = labels.replace({'Win': 2}, regex=True)\n",
    "labels = labels.drop('match', axis=1)\n",
    "\n",
    "\n",
    "features = pd.read_csv(\"features.csv\")\n",
    "features.rename( columns={'Unnamed: 0':'match'}, inplace=True )\n",
    "features = features.drop('match', axis=1)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K cross fold validation\n",
    "\n",
    "To test how well our model is able to get trained by some data and then predict data it hasn't seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Train, Validation\n",
    "\n",
    "X = np.array(features)\n",
    "y = np.array(labels['label'])\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "counter = 1\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    val = features.iloc[test_index, :]\n",
    "\n",
    "    train = features.iloc[train_index, :]\n",
    "    \n",
    "    val.to_csv(os.path.join('folds' + os.sep + 'validate', str(counter) + '.csv'))\n",
    "    train.to_csv(os.path.join('folds' + os.sep + 'train', str(counter) + '.csv'))\n",
    "    \n",
    "    val_target = labels.iloc[test_index, :]\n",
    "    train_target = labels.iloc[train_index, :]\n",
    "    val_target.to_csv(os.path.join('targets' + os.sep + 'validate', str(counter) + '.csv'))\n",
    "    train_target.to_csv(os.path.join('targets' + os.sep + 'train', str(counter) + '.csv'))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>KNN Algorithm</h3>\n",
    "<p> K-nearest neighbors with an Euclidean distance measure is sensitive to magnitudes and hence should be scaled for all features to weigh in equally.</p>\n",
    "<p>The following one is with using 20% of the entries for test and the rest to train</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61 49 55]\n",
      " [54 29 54]\n",
      " [98 44 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.37      0.32       165\n",
      "           1       0.24      0.21      0.22       137\n",
      "           2       0.43      0.37      0.40       224\n",
      "\n",
      "    accuracy                           0.33       526\n",
      "   macro avg       0.32      0.32      0.31       526\n",
      "weighted avg       0.33      0.33      0.33       526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(features, labels, test_size=0.20)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X1_train)\n",
    "\n",
    "X1_train = scaler.transform(X1_train)\n",
    "X1_test = scaler.transform(X1_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, Y1_train)\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "print(confusion_matrix(Y1_test, y1_pred))\n",
    "print(classification_report(Y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Using k-fold cross validation:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43155894 0.42585551 0.46666667 0.41333333 0.43809524]\n",
      "cv_scores mean:0.4351019373528879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=5)\n",
    "cv_scores = cross_val_score(knn_cv, features, labels, cv=5)\n",
    "print(cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "knn2 = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "knn_gscv.fit(features, labels)\n",
    "#knn_gscv.best_params_\n",
    "knn_gscv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We should test different K values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nerror_rate = []\\nfor i in range(1,40):\\n\\n    knn = KNeighborsClassifier(n_neighbors=i)\\n    knn.fit(X_train,Y_train)\\n    pred_i = knn.predict(X_test)\\n    error_rate.append(np.mean(pred_i != Y_test))\\n    \\nplt.figure(figsize=(12, 6))\\nplt.plot(range(1, 40), error_rate, color='red', linestyle='dashed', marker='o',\\n         markerfacecolor='blue', markersize=10)\\nplt.title('Error Rate K Value')\\nplt.xlabel('K Value')\\nplt.ylabel('Mean Error')\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "error_rate = []\n",
    "for i in range(1,40):\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,Y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != Y_test))\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error_rate, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0510 14:29:50.966262 19220 deprecation.py:506] From C:\\Users\\35192\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 77,683\n",
      "Trainable params: 77,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            8, activation=\"relu\", input_shape=(features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2101, 31)\n",
      "(2101, 3)\n",
      "Train on 2101 samples, validate on 526 samples\n",
      "Epoch 1/30\n",
      "2101/2101 [==============================] - 1s 251us/sample - loss: 1.0247 - acc: 0.4902 - val_loss: 1.0274 - val_acc: 0.4810\n",
      "Epoch 2/30\n",
      "2101/2101 [==============================] - 0s 24us/sample - loss: 1.0176 - acc: 0.5093 - val_loss: 1.0349 - val_acc: 0.4734\n",
      "Epoch 3/30\n",
      "2101/2101 [==============================] - 0s 21us/sample - loss: 1.0144 - acc: 0.5012 - val_loss: 1.0165 - val_acc: 0.4829\n",
      "Epoch 4/30\n",
      "2101/2101 [==============================] - 0s 21us/sample - loss: 1.0056 - acc: 0.5131 - val_loss: 1.0335 - val_acc: 0.4848\n",
      "Epoch 5/30\n",
      "2101/2101 [==============================] - 0s 22us/sample - loss: 1.0091 - acc: 0.5021 - val_loss: 1.0225 - val_acc: 0.4848\n",
      "Epoch 6/30\n",
      "2101/2101 [==============================] - 0s 25us/sample - loss: 1.0102 - acc: 0.5083 - val_loss: 1.0158 - val_acc: 0.4753\n",
      "Epoch 7/30\n",
      "2101/2101 [==============================] - 0s 23us/sample - loss: 1.0162 - acc: 0.5031 - val_loss: 1.0177 - val_acc: 0.4810\n",
      "Epoch 8/30\n",
      "2101/2101 [==============================] - 0s 22us/sample - loss: 1.0101 - acc: 0.5150 - val_loss: 1.0222 - val_acc: 0.4829\n",
      "Epoch 9/30\n",
      "2101/2101 [==============================] - 0s 22us/sample - loss: 1.0101 - acc: 0.5093 - val_loss: 1.0320 - val_acc: 0.4867\n",
      "Epoch 10/30\n",
      "2101/2101 [==============================] - 0s 21us/sample - loss: 1.0087 - acc: 0.5083 - val_loss: 1.0267 - val_acc: 0.4829\n",
      "Epoch 11/30\n",
      "2101/2101 [==============================] - 0s 23us/sample - loss: 1.0078 - acc: 0.5036 - val_loss: 1.0234 - val_acc: 0.4848\n",
      "Epoch 12/30\n",
      "2101/2101 [==============================] - 0s 20us/sample - loss: 1.0064 - acc: 0.5083 - val_loss: 1.0245 - val_acc: 0.4943\n",
      "Epoch 13/30\n",
      "2101/2101 [==============================] - 0s 22us/sample - loss: 1.0035 - acc: 0.5088 - val_loss: 1.0183 - val_acc: 0.4905\n",
      "Epoch 14/30\n",
      "2101/2101 [==============================] - 0s 22us/sample - loss: 1.0035 - acc: 0.5112 - val_loss: 1.0404 - val_acc: 0.4829\n",
      "Epoch 15/30\n",
      "2101/2101 [==============================] - 0s 21us/sample - loss: 1.0046 - acc: 0.5079 - val_loss: 1.0230 - val_acc: 0.4886\n",
      "Epoch 16/30\n",
      "2101/2101 [==============================] - 0s 21us/sample - loss: 1.0058 - acc: 0.5088 - val_loss: 1.0244 - val_acc: 0.4886\n",
      "Epoch 17/30\n",
      "2101/2101 [==============================] - 0s 24us/sample - loss: 1.0001 - acc: 0.5121 - val_loss: 1.0276 - val_acc: 0.4848\n",
      "Epoch 18/30\n",
      "2101/2101 [==============================] - 0s 22us/sample - loss: 1.0049 - acc: 0.5102 - val_loss: 1.0160 - val_acc: 0.4924\n",
      "Epoch 19/30\n",
      "2101/2101 [==============================] - 0s 20us/sample - loss: 1.0086 - acc: 0.5126 - val_loss: 1.0230 - val_acc: 0.4791\n",
      "Epoch 20/30\n",
      "2101/2101 [==============================] - 0s 20us/sample - loss: 1.0015 - acc: 0.5126 - val_loss: 1.0052 - val_acc: 0.4829\n",
      "Epoch 21/30\n",
      "2101/2101 [==============================] - 0s 20us/sample - loss: 1.0058 - acc: 0.5121 - val_loss: 1.0134 - val_acc: 0.4867\n",
      "Epoch 22/30\n",
      "2101/2101 [==============================] - 0s 24us/sample - loss: 0.9987 - acc: 0.5183 - val_loss: 1.0159 - val_acc: 0.4848\n",
      "Epoch 23/30\n",
      "2101/2101 [==============================] - 0s 21us/sample - loss: 0.9978 - acc: 0.5140 - val_loss: 1.0227 - val_acc: 0.4848\n",
      "Epoch 24/30\n",
      "2101/2101 [==============================] - 0s 24us/sample - loss: 1.0022 - acc: 0.5145 - val_loss: 1.0104 - val_acc: 0.4886\n",
      "Epoch 25/30\n",
      "2101/2101 [==============================] - 0s 20us/sample - loss: 1.0035 - acc: 0.5140 - val_loss: 1.0088 - val_acc: 0.4905\n",
      "Epoch 26/30\n",
      "2101/2101 [==============================] - 0s 20us/sample - loss: 1.0004 - acc: 0.5164 - val_loss: 1.0211 - val_acc: 0.4848\n",
      "Epoch 27/30\n",
      "2101/2101 [==============================] - 0s 21us/sample - loss: 0.9909 - acc: 0.5155 - val_loss: 1.0312 - val_acc: 0.4924\n",
      "Epoch 28/30\n",
      "2101/2101 [==============================] - 0s 22us/sample - loss: 0.9991 - acc: 0.5169 - val_loss: 1.0291 - val_acc: 0.4848\n",
      "Epoch 29/30\n",
      "2101/2101 [==============================] - 0s 20us/sample - loss: 0.9969 - acc: 0.5174 - val_loss: 1.0313 - val_acc: 0.4886\n",
      "Epoch 30/30\n",
      "2101/2101 [==============================] - 0s 19us/sample - loss: 1.0001 - acc: 0.5136 - val_loss: 1.0224 - val_acc: 0.4867\n"
     ]
    }
   ],
   "source": [
    "fold = \"1\"\n",
    "\n",
    "train_features = pd.read_csv(os.path.join('folds' + os.sep + 'train', fold + '.csv')).drop('Unnamed: 0', axis=1)\n",
    "train_targets = to_categorical(pd.read_csv(os.path.join('targets' + os.sep + 'train', fold + '.csv')).drop('Unnamed: 0', axis=1))\n",
    "val_features = pd.read_csv(os.path.join('folds' + os.sep + 'validate', fold + '.csv')).drop('Unnamed: 0', axis=1)\n",
    "val_targets = to_categorical(pd.read_csv(os.path.join('targets' + os.sep + 'validate', fold + '.csv')).drop('Unnamed: 0', axis=1))\n",
    "\n",
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "opt = RMSprop(\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "   loss='categorical_crossentropy', optimizer=opt, metrics=['acc']\n",
    ")\n",
    "\n",
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_targets.shape)\n",
    "\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=1024,\n",
    "    epochs=30,\n",
    "    validation_data=(val_features, val_targets),\n",
    ")\n",
    "\n",
    "# Save weights\n",
    "model.save_weights(os.path.join('weights' + os.sep + 'custom', fold + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plot history\n",
    "acc = smooth_curve(history.history['acc'])\n",
    "val_acc = smooth_curve(history.history['val_acc'])\n",
    "loss = smooth_curve(history.history['loss'])\n",
    "val_loss = smooth_curve(history.history['val_loss'])\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "axs[0].plot(epochs, acc, 'bo', label='Training_acc')\n",
    "axs[0].plot(epochs, val_acc, 'b', label='Validation_acc')\n",
    "axs[0].legend()\n",
    "axs[1].plot(epochs, loss, 'bo', label='Training_loss')\n",
    "axs[1].plot(epochs, val_loss, 'b', label='Validation_loss')\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
